# LLMå¹»è§‰æ ¡éªŒæœºåˆ¶ä¸åŠŸèƒ½å¢å¼ºæ–¹æ¡ˆ

## é—®é¢˜2ï¼šç°æœ‰LLMå¹»è§‰æ ¡éªŒæœºåˆ¶åˆ†æ

### å½“å‰å¤šå±‚æ ¡éªŒæ¶æ„ (Check Layer)

ç³»ç»Ÿå·²å®ç° **3å±‚æ ¡éªŒæœºåˆ¶** é˜²æ­¢LLMå¹»è§‰ï¼š

#### Layer 1: å­¦æœ¯æ¦‚å¿µè¿‡æ»¤ (Academic Concept Filter)
**ä½ç½®**: [`backend/api/real_node_generator.py:283`](../backend/api/real_node_generator.py#L283)

```python
async def is_academic_concept(concept: str) -> bool:
    """ä½¿ç”¨LLMäºŒå…ƒåˆ†ç±»åˆ¤æ–­æ˜¯å¦ä¸ºå­¦æœ¯æ¦‚å¿µ"""
    prompt = f'"{concept}"æ˜¯å­¦æœ¯æ¦‚å¿µå—ï¼Ÿå›ç­”"æ˜¯"æˆ–"å¦"'
    # ä½¿ç”¨ä½temperatureç¡®ä¿ç¡®å®šæ€§è¾“å‡º
    temperature=0.1, max_tokens=10
```

**æ ¡éªŒé€»è¾‘**:
- âœ… è¿‡æ»¤éå­¦æœ¯å†…å®¹ï¼ˆå¦‚"ç¬¨è›‹"ã€"å¥½ç©"ç­‰ï¼‰
- âœ… ä½¿ç”¨æä½temperature (0.1) æé«˜åˆ¤æ–­ç¨³å®šæ€§
- âœ… äºŒå…ƒè¾“å‡ºå‡å°‘å¹»è§‰ç©ºé—´

**å±€é™æ€§**:
- âš ï¸ æœªåœ¨ä¸»æµç¨‹ä¸­å¼ºåˆ¶è°ƒç”¨ï¼ˆæµ‹è¯•ä»£ç ä¸­å­˜åœ¨ä½†æœªå¯ç”¨ï¼‰
- âš ï¸ å¯¹è¾¹ç¼˜å­¦æœ¯æ¦‚å¿µå¯èƒ½è¯¯åˆ¤

---

#### Layer 2: WikipediaçŸ¥è¯†åº“éªŒè¯ (Knowledge Base Validation)
**ä½ç½®**: [`backend/api/routes.py:148`](../backend/api/routes.py#L148)

```python
async def get_wikipedia_definition(concept: str) -> Dict:
    """åŒè¯­WikipediaæŸ¥è¯¢ï¼ˆä¸­æ–‡â†’è‹±æ–‡fallbackï¼‰"""
    # 1. æŸ¥è¯¢ä¸­æ–‡Wikipedia
    # 2. å¤±è´¥åˆ™æŸ¥è¯¢è‹±æ–‡Wikipedia
    # 3. è¿”å›existsæ ‡å¿—å’Œæƒå¨å®šä¹‰
```

**æ ¡éªŒé€»è¾‘**:
- âœ… **æ‰€æœ‰æ¦‚å¿µå¼ºåˆ¶éªŒè¯** - ä¸­å¿ƒèŠ‚ç‚¹å’Œæ‰©å±•èŠ‚ç‚¹å‡éªŒè¯
- âœ… åŒè¯­æŸ¥è¯¢ - ä¸­æ–‡å¤±è´¥æ—¶è‡ªåŠ¨å°è¯•è‹±æ–‡
- âœ… å¤„ç†æ­§ä¹‰é¡µé¢ - è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªé€‰é¡¹
- âœ… å¯ä¿¡åº¦åŠ æƒ - Wikipediaå­˜åœ¨çš„æ¦‚å¿µåŸºç¡€å¯ä¿¡åº¦0.95ï¼Œå¦åˆ™0.70

**æ•ˆæœ**:
```python
# æœ‰Wikipediaå®šä¹‰
credibility_base = 0.95  # é«˜å¯ä¿¡åº¦

# æ— Wikipediaå®šä¹‰ï¼ˆLLMç”Ÿæˆï¼‰
credibility_base = 0.70  # é™çº§å¯ä¿¡åº¦
```

---

#### Layer 3: è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº (Semantic Similarity Ranking)
**ä½ç½®**: [`backend/api/routes.py:310-390`](../backend/api/routes.py#L310-L390)

```python
# æ•°æ®æµ:
# 1. LLMç”Ÿæˆ2å€å€™é€‰æ¦‚å¿µ
# 2. è®¡ç®—æ¯ä¸ªå€™é€‰ä¸è¾“å…¥æ¦‚å¿µçš„è¯­ä¹‰ç›¸ä¼¼åº¦
# 3. æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
# 4. åŠ¨æ€é˜ˆå€¼ç­›é€‰ï¼ˆä¿è¯3-9ä¸ªèŠ‚ç‚¹ï¼‰
SIMILARITY_THRESHOLD = 0.62
```

**æ ¡éªŒé€»è¾‘**:
- âœ… **è¿‡åº¦ç”Ÿæˆ+æ’åºç­›é€‰** - ç”Ÿæˆ20ä¸ªå€™é€‰ï¼Œé€‰æ‹©10ä¸ªæœ€ç›¸å…³
- âœ… **OpenAI Embeddings** - ä½¿ç”¨text-embedding-3-smallè®¡ç®—çœŸå®è¯­ä¹‰ç›¸ä¼¼åº¦
- âœ… **åŠ¨æ€é˜ˆå€¼** - ç›¸ä¼¼åº¦<0.62çš„æ¦‚å¿µè¢«è¿‡æ»¤
- âœ… **æ•°é‡æ§åˆ¶** - ç¡®ä¿3-9ä¸ªé«˜è´¨é‡èŠ‚ç‚¹

**é˜²å¹»è§‰æ•ˆæœ**:
```python
å€™é€‰æ¦‚å¿µ: 20ä¸ª
â†“ è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
â†“ æ’åº + é˜ˆå€¼ç­›é€‰ (>0.62)
æœ€ç»ˆè¾“å‡º: 3-9ä¸ªé«˜ç›¸å…³æ€§æ¦‚å¿µ
```

---

### ç°æœ‰æœºåˆ¶çš„ä¼˜åŠ¿

| æ ¡éªŒå±‚ | é˜²å¹»è§‰æ•ˆæœ | æ€§èƒ½å¼€é”€ | è¦†ç›–ç‡ |
|-------|-----------|---------|--------|
| **å­¦æœ¯æ¦‚å¿µè¿‡æ»¤** | â­â­â­ | ä½ (1æ¬¡LLMè°ƒç”¨) | æœªå¯ç”¨ |
| **WikipediaéªŒè¯** | â­â­â­â­â­ | ä¸­ (ç½‘ç»œæŸ¥è¯¢) | 100% |
| **è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº** | â­â­â­â­ | é«˜ (Embeddingè®¡ç®—) | 100% |

---

### æ”¹è¿›æ–¹æ¡ˆ

#### æ”¹è¿›ç‚¹1: å¯ç”¨å­¦æœ¯æ¦‚å¿µè¿‡æ»¤å™¨

**é—®é¢˜**: ç›®å‰`is_academic_concept()`ä»…å­˜åœ¨äºæµ‹è¯•ä»£ç ï¼Œæœªåœ¨ä¸»æµç¨‹ä¸­è°ƒç”¨

**æ–¹æ¡ˆ**: åœ¨ç”Ÿæˆæ¦‚å¿µåç«‹å³è¿‡æ»¤

```python
# backend/api/real_node_generator.py ç¬¬157è¡Œåæ·»åŠ 
if concepts:
    # æ·»åŠ å­¦æœ¯æ¦‚å¿µè¿‡æ»¤
    filtered_concepts = []
    for concept in concepts:
        if await is_academic_concept(concept["name"]):
            filtered_concepts.append(concept)
        else:
            print(f"[FILTER] éå­¦æœ¯æ¦‚å¿µå·²è¿‡æ»¤: {concept['name']}")
    concepts = filtered_concepts
    print(f"[SUCCESS] å­¦æœ¯è¿‡æ»¤åå‰©ä½™{len(concepts)}ä¸ªæ¦‚å¿µ")
```

**æ•ˆæœ**: 
- è¿‡æ»¤"AIå¥³å‹"ã€"é‡å­ç‚’è‚¡"ç­‰ä¼ªå­¦æœ¯æ¦‚å¿µ
- é˜²æ­¢LLMç”Ÿæˆè¥é”€/å¨±ä¹å†…å®¹

---

#### æ”¹è¿›ç‚¹2: è·¨åŸŸçŸ¥è¯†åº“éªŒè¯

**é—®é¢˜**: ä»…ä¾èµ–Wikipediaï¼Œå­¦æœ¯é¢†åŸŸè¦†ç›–ä¸è¶³ï¼ˆå¦‚å‰æ²¿ç ”ç©¶ã€å†·é—¨å­¦ç§‘ï¼‰

**æ–¹æ¡ˆ**: é›†æˆå­¦æœ¯æ•°æ®åº“API

```python
async def verify_academic_concept(concept: str) -> Dict:
    """å¤šæºéªŒè¯å­¦æœ¯æ¦‚å¿µ"""
    # 1. Wikipediaï¼ˆé€šç”¨çŸ¥è¯†ï¼‰
    wiki_result = await get_wikipedia_definition(concept)
    
    # 2. arXiv APIï¼ˆå‰æ²¿ç ”ç©¶ï¼‰
    arxiv_result = await search_arxiv(concept, max_results=1)
    
    # 3. Semantic Scholarï¼ˆå­¦æœ¯æ–‡çŒ®ï¼‰
    scholar_result = await search_semantic_scholar(concept, limit=1)
    
    # ç»¼åˆå¯ä¿¡åº¦
    exists = wiki_result["exists"] or len(arxiv_result) > 0 or len(scholar_result) > 0
    credibility = 0.95 if exists else 0.60  # ä¸‰æºå‡æ— åˆ™é™è‡³0.60
    
    return {"exists": exists, "credibility": credibility, "sources": [...]}
```

**æ•ˆæœ**:
- è¦†ç›–å‰æ²¿æ¦‚å¿µï¼ˆå¦‚"æ‰©æ•£æ¨¡å‹"ã€"é‡å­çº é”™ç "ï¼‰
- å¤šæºäº¤å‰éªŒè¯ï¼Œé™ä½å•ä¸€æ•°æ®æºåå·®

---

#### æ”¹è¿›ç‚¹3: LLMè‡ªæ ¡éªŒï¼ˆSelf-Verificationï¼‰

**é—®é¢˜**: ç”Ÿæˆçš„è·¨å­¦ç§‘å…³è”å¯èƒ½è¿‡äºç‰µå¼º

**æ–¹æ¡ˆ**: äºŒæ¬¡LLMè°ƒç”¨éªŒè¯å…³è”åˆç†æ€§

```python
async def verify_cross_discipline_relation(
    concept1: str, 
    concept2: str, 
    relation: str
) -> float:
    """ä½¿ç”¨LLMè¯„ä¼°è·¨å­¦ç§‘å…³è”çš„åˆç†æ€§"""
    
    prompt = f"""
ä½ æ˜¯è·¨å­¦ç§‘ç ”ç©¶ä¸“å®¶ã€‚è¯„ä¼°ä»¥ä¸‹è·¨å­¦ç§‘å…³è”çš„åˆç†æ€§ï¼š

æ¦‚å¿µ1: {concept1}
æ¦‚å¿µ2: {concept2}
å…³ç³»: {relation}

åˆç†æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š
- 0-3åˆ†ï¼šå…³è”ç‰µå¼ºï¼Œç¼ºä¹å­¦æœ¯ä¾æ®
- 4-6åˆ†ï¼šå…³è”å­˜åœ¨ï¼Œä½†è¾ƒå¼±
- 7-10åˆ†ï¼šå…³è”ç´§å¯†ï¼Œæœ‰æ˜ç¡®å­¦æœ¯ä¾æ®

ä»…è¾“å‡º0-10çš„æ•´æ•°åˆ†æ•°ï¼š
"""
    
    response = await llm_client.chat.completions.create(
        model="google/gemini-3-flash-preview",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        max_tokens=5
    )
    
    score = int(response.choices[0].message.content.strip())
    return score / 10.0  # å½’ä¸€åŒ–åˆ°[0, 1]
```

**ä½¿ç”¨åœºæ™¯**:
```python
# åœ¨ç”Ÿæˆæ¦‚å¿µåéªŒè¯
for candidate in candidates:
    verification_score = await verify_cross_discipline_relation(
        concept, candidate["name"], candidate["relation"]
    )
    
    if verification_score < 0.4:  # ä½äº4åˆ†çš„å…³è”ä¸¢å¼ƒ
        print(f"[FILTER] å…³è”ä¸åˆç†: {candidate['name']} ({verification_score:.2f})")
        continue
    
    candidate["verification_score"] = verification_score
```

**æ•ˆæœ**:
- è¿‡æ»¤"ç¥ç»ç½‘ç»œ â†’ ç¤¾äº¤ç½‘ç»œ"ç­‰å¼±å…³è”
- LLMè‡ªæˆ‘çº é”™æœºåˆ¶

---

#### æ”¹è¿›ç‚¹4: äººå·¥åé¦ˆå¾ªç¯ï¼ˆHuman-in-the-Loopï¼‰

**é—®é¢˜**: å®Œå…¨è‡ªåŠ¨åŒ–æ— æ³•å¤„ç†è¾¹ç¼˜æ¡ˆä¾‹

**æ–¹æ¡ˆ**: æ·»åŠ ç”¨æˆ·åé¦ˆæœºåˆ¶

```python
# å‰ç«¯äº¤äº’
ç”¨æˆ·ç‚¹å‡»èŠ‚ç‚¹ â†’ æ ‡è®°ä¸º"ä¸ç›¸å…³" â†’ åç«¯è®°å½• â†’ ä¸‹æ¬¡ç”Ÿæˆæ—¶é™æƒ

# åç«¯å®ç°
class ConceptFeedback:
    async def mark_irrelevant(self, concept: str, parent: str):
        """ç”¨æˆ·æ ‡è®°ä¸ç›¸å…³çš„æ¦‚å¿µå¯¹"""
        await redis_client.sadd(f"irrelevant:{parent}", concept)
    
    async def get_blacklist(self, parent: str) -> Set[str]:
        """è·å–ç”¨æˆ·æ ‡è®°çš„é»‘åå•"""
        return await redis_client.smembers(f"irrelevant:{parent}")

# åœ¨ç”Ÿæˆæ—¶è¿‡æ»¤
blacklist = await feedback.get_blacklist(concept)
candidates = [c for c in candidates if c["name"] not in blacklist]
```

**æ•ˆæœ**:
- ä¸ªæ€§åŒ–è¿‡æ»¤
- æŒç»­å­¦ä¹ ï¼Œè¶Šç”¨è¶Šå‡†

---

### æ¨èå®æ–½ä¼˜å…ˆçº§

| æ”¹è¿›æ–¹æ¡ˆ | ä¼˜å…ˆçº§ | å®æ–½éš¾åº¦ | æ•ˆæœ | å»ºè®® |
|---------|-------|---------|------|------|
| **å¯ç”¨å­¦æœ¯æ¦‚å¿µè¿‡æ»¤** | ğŸ”´ é«˜ | â­ ä½ | â­â­â­ | **ç«‹å³å®æ–½** |
| **LLMè‡ªæ ¡éªŒ** | ğŸŸ¡ ä¸­ | â­â­ ä¸­ | â­â­â­â­ | **æ¨èå®æ–½** |
| **å¤šæºçŸ¥è¯†åº“éªŒè¯** | ğŸŸ¢ ä½ | â­â­â­ é«˜ | â­â­â­â­â­ | é•¿æœŸä¼˜åŒ– |
| **äººå·¥åé¦ˆå¾ªç¯** | ğŸŸ¢ ä½ | â­â­ ä¸­ | â­â­â­â­ | äº§å“åŒ–åå®æ–½ |

---

## æ€»ç»“

### ç°æœ‰æœºåˆ¶å·²ç»ç›¸å½“å®Œå–„ï¼š
âœ… Wikipediaæƒå¨éªŒè¯ï¼ˆ100%è¦†ç›–ï¼‰  
âœ… è¯­ä¹‰ç›¸ä¼¼åº¦æ’åºï¼ˆé˜²æ­¢ç¦»é¢˜ï¼‰  
âœ… åŠ¨æ€å¯ä¿¡åº¦è®¡ç®—ï¼ˆé£é™©é‡åŒ–ï¼‰  

### æ”¹è¿›ç©ºé—´ï¼š
âš ï¸ å­¦æœ¯æ¦‚å¿µè¿‡æ»¤æœªå¯ç”¨ï¼ˆä»£ç å·²å­˜åœ¨ï¼‰  
âš ï¸ ç¼ºå°‘LLMè‡ªæ ¡éªŒæœºåˆ¶  
âš ï¸ å•ä¸€çŸ¥è¯†æºï¼ˆä»…Wikipediaï¼‰  

### å»ºè®®ï¼š
**çŸ­æœŸ**ï¼ˆæœ¬æ¬¡è¿­ä»£ï¼‰ï¼šå¯ç”¨å­¦æœ¯æ¦‚å¿µè¿‡æ»¤  
**ä¸­æœŸ**ï¼ˆä¸‹ä¸ªç‰ˆæœ¬ï¼‰ï¼šæ·»åŠ LLMè‡ªæ ¡éªŒ  
**é•¿æœŸ**ï¼ˆäº§å“åŒ–ï¼‰ï¼šå¤šæºéªŒè¯ + ç”¨æˆ·åé¦ˆ

---

## é—®é¢˜3ï¼šåŠŸèƒ½2å’ŒåŠŸèƒ½3è®¾è®¡æ–¹æ¡ˆ

è¯¦è§ä¸‹ä¸€èŠ‚...
