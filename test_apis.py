"""
æµ‹è¯•ç»´åŸºç™¾ç§‘APIå’ŒArxiv APIåŠŸèƒ½
ä½¿ç”¨ py -3.11 test_apis.py è¿è¡Œ
"""

import asyncio
import sys


async def test_wikipedia_api():
    """æµ‹è¯•ç»´åŸºç™¾ç§‘API"""
    print("\n" + "="*60)
    print("æµ‹è¯•ç»´åŸºç™¾ç§‘API")
    print("="*60)
    
    try:
        import wikipedia
        
        # æµ‹è¯•ä¸­æ–‡ç»´åŸºç™¾ç§‘
        test_concepts = ["ç†µ", "ç¥ç»ç½‘ç»œ", "é‡å­è®¡ç®—", "æ·±åº¦å­¦ä¹ "]
        
        for concept in test_concepts:
            print(f"\nğŸ” æœç´¢: {concept}")
            try:
                wikipedia.set_lang("zh")
                page = wikipedia.page(concept)
                summary = page.summary[:200] + "..." if len(page.summary) > 200 else page.summary
                print(f"   âœ… æ‰¾åˆ°: {page.title}")
                print(f"   ğŸ“– æ‘˜è¦: {summary}")
                print(f"   ğŸ”— é“¾æ¥: {page.url}")
            except wikipedia.exceptions.DisambiguationError as e:
                print(f"   âš ï¸ æ­§ä¹‰é¡µé¢ï¼Œé€‰é¡¹: {e.options[:3]}")
                # å°è¯•ç¬¬ä¸€ä¸ªé€‰é¡¹
                if e.options:
                    page = wikipedia.page(e.options[0])
                    print(f"   âœ… é€‰æ‹©: {page.title}")
            except wikipedia.exceptions.PageError:
                print(f"   âŒ ä¸­æ–‡æœªæ‰¾åˆ°ï¼Œå°è¯•è‹±æ–‡...")
                try:
                    wikipedia.set_lang("en")
                    page = wikipedia.page(concept)
                    print(f"   âœ… è‹±æ–‡æ‰¾åˆ°: {page.title}")
                except:
                    print(f"   âŒ è‹±æ–‡ä¹Ÿæœªæ‰¾åˆ°")
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
        
        print("\nâœ… ç»´åŸºç™¾ç§‘APIæµ‹è¯•å®Œæˆ!")
        return True
        
    except ImportError:
        print("âŒ wikipediaåŒ…æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: py -3.11 -m pip install wikipedia")
        return False


async def test_arxiv_api():
    """æµ‹è¯•Arxiv API"""
    print("\n" + "="*60)
    print("æµ‹è¯•Arxiv API")
    print("="*60)
    
    try:
        import httpx
        import xml.etree.ElementTree as ET
        
        # ä½¿ç”¨HTTPS URL
        arxiv_url = "https://export.arxiv.org/api/query"
        test_queries = ["entropy", "neural network", "quantum computing", "deep learning"]
        
        async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
            for query in test_queries:
                print(f"\nğŸ” æœç´¢: {query}")
                
                params = {
                    "search_query": f"all:{query}",
                    "start": 0,
                    "max_results": 3,
                    "sortBy": "relevance",
                    "sortOrder": "descending"
                }
                
                try:
                    response = await client.get(arxiv_url, params=params)
                    
                    if response.status_code == 200:
                        # è§£æXML
                        root = ET.fromstring(response.text)
                        ns = {
                            'atom': 'http://www.w3.org/2005/Atom',
                            'arxiv': 'http://arxiv.org/schemas/atom'
                        }
                        
                        entries = root.findall('atom:entry', ns)
                        print(f"   âœ… æ‰¾åˆ° {len(entries)} ç¯‡è®ºæ–‡")
                        
                        for i, entry in enumerate(entries[:2], 1):
                            title = entry.find('atom:title', ns)
                            link = entry.find('atom:id', ns)
                            
                            if title is not None:
                                title_text = title.text.strip().replace('\n', ' ')[:80]
                                print(f"   ğŸ“„ [{i}] {title_text}...")
                            if link is not None:
                                print(f"       ğŸ”— {link.text.strip()}")
                    else:
                        print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                        
                except Exception as e:
                    print(f"   âŒ è¯·æ±‚å¤±è´¥: {e}")
        
        print("\nâœ… Arxiv APIæµ‹è¯•å®Œæˆ!")
        return True
        
    except ImportError:
        print("âŒ httpxåŒ…æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: py -3.11 -m pip install httpx")
        return False


async def test_backend_api():
    """æµ‹è¯•åç«¯API"""
    print("\n" + "="*60)
    print("æµ‹è¯•åç«¯APIè¿æ¥")
    print("="*60)
    
    try:
        import httpx
        
        base_url = "http://localhost:8888"
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            # æµ‹è¯•æ ¹è·¯å¾„
            print("\nğŸ” æµ‹è¯•æ ¹è·¯å¾„...")
            try:
                response = await client.get(f"{base_url}/")
                if response.status_code == 200:
                    print(f"   âœ… æ ¹è·¯å¾„: {response.json()}")
                else:
                    print(f"   âŒ çŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                print(f"   âŒ è¿æ¥å¤±è´¥: {e}")
                print("   ğŸ’¡ è¯·å…ˆå¯åŠ¨åç«¯: cd backend && py -3.11 -m uvicorn main:app --reload --port 8888")
                return False
            
            # æµ‹è¯•å¥åº·æ£€æŸ¥
            print("\nğŸ” æµ‹è¯•å¥åº·æ£€æŸ¥...")
            try:
                response = await client.get(f"{base_url}/health")
                if response.status_code == 200:
                    print(f"   âœ… å¥åº·çŠ¶æ€: {response.json()}")
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
            
            # æµ‹è¯•å‘ç°æ¥å£
            print("\nğŸ” æµ‹è¯•æ¦‚å¿µå‘ç°æ¥å£ (ç†µ)...")
            try:
                response = await client.post(
                    f"{base_url}/api/v1/discover",
                    json={"concept": "ç†µ", "depth": 1, "max_concepts": 10},
                    timeout=120.0
                )
                if response.status_code == 200:
                    data = response.json()
                    print(f"   âœ… çŠ¶æ€: {data.get('status')}")
                    if 'data' in data and 'nodes' in data['data']:
                        nodes = data['data']['nodes']
                        print(f"   ğŸ“Š å‘ç° {len(nodes)} ä¸ªèŠ‚ç‚¹")
                        for node in nodes[:3]:
                            source = node.get('source', 'LLM')
                            print(f"      - {node['label']} ({node['discipline']}) [æ¥æº: {source}]")
                else:
                    print(f"   âŒ çŠ¶æ€ç : {response.status_code}")
                    print(f"   ğŸ“ å“åº”: {response.text[:200]}")
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
            
            # æµ‹è¯•Arxivæœç´¢æ¥å£
            print("\nğŸ” æµ‹è¯•Arxivæœç´¢æ¥å£...")
            try:
                response = await client.get(
                    f"{base_url}/api/v1/arxiv/search",
                    params={"query": "entropy", "max_results": 3},
                    timeout=30.0
                )
                if response.status_code == 200:
                    data = response.json()
                    print(f"   âœ… æ‰¾åˆ° {data['data']['total']} ç¯‡è®ºæ–‡")
                    for paper in data['data']['papers'][:2]:
                        print(f"      - {paper['title'][:60]}...")
                else:
                    print(f"   âŒ çŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
            
            # æµ‹è¯•æ¦‚å¿µè¯¦æƒ…æ¥å£
            print("\nğŸ” æµ‹è¯•æ¦‚å¿µè¯¦æƒ…æ¥å£...")
            try:
                response = await client.get(
                    f"{base_url}/api/v1/concept/ç†µ/detail",
                    timeout=60.0
                )
                if response.status_code == 200:
                    data = response.json()
                    print(f"   âœ… è·å–æˆåŠŸ")
                    print(f"      - ç»´åŸºå®šä¹‰: {data['data']['wiki_definition'][:100] if data['data']['wiki_definition'] else 'æ— '}...")
                    print(f"      - ç›¸å…³è®ºæ–‡: {data['data']['papers_count']} ç¯‡")
                else:
                    print(f"   âŒ çŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
        
        print("\nâœ… åç«¯APIæµ‹è¯•å®Œæˆ!")
        return True
        
    except ImportError:
        print("âŒ httpxåŒ…æœªå®‰è£…")
        return False


async def main():
    print("="*60)
    print("ConceptGraph AI - APIåŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•ç»´åŸºç™¾ç§‘API
    wiki_ok = await test_wikipedia_api()
    
    # æµ‹è¯•Arxiv API
    arxiv_ok = await test_arxiv_api()
    
    # æµ‹è¯•åç«¯API
    backend_ok = await test_backend_api()
    
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    print(f"ç»´åŸºç™¾ç§‘API: {'âœ… é€šè¿‡' if wiki_ok else 'âŒ å¤±è´¥'}")
    print(f"Arxiv API: {'âœ… é€šè¿‡' if arxiv_ok else 'âŒ å¤±è´¥'}")
    print(f"åç«¯API: {'âœ… é€šè¿‡' if backend_ok else 'âŒ å¤±è´¥'}")
    
    if not backend_ok:
        print("\nğŸ’¡ å¯åŠ¨åç«¯çš„å‘½ä»¤:")
        print("   cd D:\\yunjisuanfinal\\backend")
        print("   py -3.11 -m uvicorn main:app --reload --port 8888")


if __name__ == "__main__":
    asyncio.run(main())
