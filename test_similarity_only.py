#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•åªä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦çš„ç­›é€‰å’Œå±•ç¤ºé€»è¾‘
"""

import asyncio
import httpx
import json

BASE_URL = "http://localhost:8000/api/v1"


async def test_similarity_only_mode():
    """æµ‹è¯•åªç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ¨¡å¼"""
    print("\n" + "="*80)
    print("æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼åº¦ç­›é€‰æ¨¡å¼")
    print("="*80)
    print("\nä¿®æ”¹å†…å®¹:")
    print("1. âŒ ç§»é™¤å¤šç»´åº¦ç›¸å…³åº¦è®¡ç®—")
    print("2. âœ… åªä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆtext-embedding-3-smallï¼‰")
    print("3. âœ… ç­›é€‰ä¾æ®ï¼šsimilarity >= 0.62")
    print("4. âœ… å±•ç¤ºåˆ†æ•°ï¼šsimilarity")
    print("5. âœ… ç§»é™¤å­—æ®µï¼šcomposite_score, relevance_dimensions, relationship_tier\n")
    
    async with httpx.AsyncClient(timeout=180.0) as client:
        response = await client.post(
            f"{BASE_URL}/discover",
            json={
                "concept": "ç¥ç»ç½‘ç»œ",
                "max_concepts": 10
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            nodes = result['data']['nodes']
            
            print(f"âœ… æµ‹è¯•æˆåŠŸï¼Œç”Ÿæˆ{len(nodes)}ä¸ªèŠ‚ç‚¹\n")
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            print("="*80)
            print("æ•°æ®ç»“æ„æ£€æŸ¥")
            print("="*80)
            
            sample_node = [n for n in nodes if n.get('depth', 0) > 0][0] if len(nodes) > 1 else None
            
            if sample_node:
                print(f"\nç¤ºä¾‹èŠ‚ç‚¹ï¼š{sample_node['label']}\n")
                print("âœ… åŒ…å«å­—æ®µ:")
                for key in sorted(sample_node.keys()):
                    value = sample_node[key]
                    if isinstance(value, (int, float)):
                        print(f"   - {key}: {value}")
                    elif isinstance(value, str) and len(value) < 50:
                        print(f"   - {key}: {value}")
                    else:
                        print(f"   - {key}: <æ•°æ®å·²çœç•¥>")
                
                # æ£€æŸ¥æ˜¯å¦ç§»é™¤äº†å¢å¼ºå­—æ®µ
                removed_fields = ["composite_score", "relevance_dimensions", "relationship_tier"]
                print("\nâŒ å·²ç§»é™¤å­—æ®µï¼ˆç¡®è®¤ï¼‰:")
                for field in removed_fields:
                    status = "âš ï¸ ä»å­˜åœ¨" if field in sample_node else "âœ… å·²ç§»é™¤"
                    print(f"   - {field}: {status}")
            
            # å±•ç¤ºæ’åºç»“æœ
            print("\n" + "="*80)
            print("èŠ‚ç‚¹æ’åºï¼ˆæŒ‰è¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰")
            print("="*80)
            
            sorted_nodes = sorted(
                [n for n in nodes if n.get('depth', 0) > 0],
                key=lambda x: x.get('similarity', 0),
                reverse=True
            )
            
            print("\næ’å | æ¦‚å¿µåç§° | è¯­ä¹‰ç›¸ä¼¼åº¦ | å¯ä¿¡åº¦ | å­¦ç§‘ | æ•°æ®æ¥æº")
            print("-" * 95)
            
            for i, node in enumerate(sorted_nodes, 1):
                name = node.get('label', 'N/A')
                sim = node.get('similarity', 0)
                cred = node.get('credibility', 0)
                disc = node.get('discipline', 'N/A')
                source = node.get('source', 'N/A')
                
                # ç›¸ä¼¼åº¦ç€è‰²
                if sim >= 0.70:
                    indicator = "ğŸŸ¢"
                elif sim >= 0.62:
                    indicator = "ğŸŸ¡"
                else:
                    indicator = "ğŸ”´"
                
                print(f"{i:2d}   | {name:18s} | {indicator} {sim:.3f}      | {cred:.3f}   | {disc:12s} | {source}")
            
            # ç»Ÿè®¡åˆ†æ
            print("\n" + "="*80)
            print("ç»Ÿè®¡åˆ†æ")
            print("="*80)
            
            similarities = [n.get('similarity', 0) for n in sorted_nodes]
            
            print(f"\nç›¸ä¼¼åº¦åˆ†å¸ƒ:")
            print(f"  æœ€é«˜: {max(similarities):.3f}")
            print(f"  æœ€ä½: {min(similarities):.3f}")
            print(f"  å¹³å‡: {sum(similarities)/len(similarities):.3f}")
            print(f"  èŒƒå›´: {max(similarities) - min(similarities):.3f}")
            
            above_threshold = [s for s in similarities if s >= 0.62]
            below_threshold = [s for s in similarities if s < 0.62]
            
            print(f"\né˜ˆå€¼ç­›é€‰ï¼ˆ0.62ï¼‰:")
            print(f"  é«˜äºé˜ˆå€¼: {len(above_threshold)}ä¸ª")
            print(f"  ä½äºé˜ˆå€¼: {len(below_threshold)}ä¸ª")
            
            if below_threshold:
                print(f"  âš ï¸ æ³¨æ„ï¼šæœ‰{len(below_threshold)}ä¸ªèŠ‚ç‚¹ä½äºé˜ˆå€¼ä½†ä»è¢«ä¿ç•™ï¼ˆå› MIN_NODES=3è¦æ±‚ï¼‰")
            
            # å¯¹æ¯”è¯´æ˜
            print("\n" + "="*80)
            print("ä¸å¤šç»´åº¦æ¨¡å¼å¯¹æ¯”")
            print("="*80)
            print("\nã€å½“å‰æ¨¡å¼ã€‘åªç”¨è¯­ä¹‰ç›¸ä¼¼åº¦:")
            print("  âœ… ä¼˜ç‚¹: è®¡ç®—å¿«é€Ÿï¼Œé€»è¾‘ä¸€è‡´ï¼Œæ— é¢å¤–LLMè°ƒç”¨")
            print("  âŒ ç¼ºç‚¹: å¯èƒ½é”™è¿‡è·¨å­¦ç§‘åŸç†ç›¸ä¼¼çš„æ¦‚å¿µ")
            print("  ğŸ“Š ç­›é€‰ä¾æ® = å±•ç¤ºåˆ†æ•° = similarity")
            
            print("\nã€ä¹‹å‰æ¨¡å¼ã€‘å¤šç»´åº¦ç»¼åˆå¾—åˆ†:")
            print("  âœ… ä¼˜ç‚¹: æ›´å¥½è¯†åˆ«è·¨å­¦ç§‘å…³è”ï¼Œè€ƒè™‘åŸç†ä¸€è‡´æ€§")
            print("  âŒ ç¼ºç‚¹: è®¡ç®—æ…¢ï¼ˆæ¯æ¦‚å¿µé¢å¤–1æ¬¡LLMè°ƒç”¨ï¼‰ï¼Œå¤æ‚åº¦é«˜")
            print("  âš ï¸ é—®é¢˜: ç­›é€‰ç”¨similarityï¼Œå±•ç¤ºç”¨composite_scoreï¼ˆä¸ä¸€è‡´ï¼ï¼‰")
                
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {response.status_code}")
            print(response.text)


if __name__ == "__main__":
    print(__doc__)
    asyncio.run(test_similarity_only_mode())
