"""
å®Œæ•´åŠŸèƒ½æµ‹è¯• - éªŒè¯é˜¶æ®µä¸€å’Œé˜¶æ®µäºŒçš„çœŸå®å¯ç”¨æ€§
ä¸åªæ£€æŸ¥ä»£ç æ­£ç¡®æ€§ï¼Œè¦çœŸæ­£éªŒè¯åŠŸèƒ½æ˜¯å¦work
"""
import asyncio
import os
import sys

# æµ‹è¯•OpenAIè¿æ¥
async def test_openai_connection():
    """æµ‹è¯•1: OpenAI APIè¿æ¥"""
    print("="*70)
    print("æµ‹è¯•1: OpenAI APIè¿æ¥")
    print("="*70)
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYæœªè®¾ç½®")
        return False
    
    print(f"âœ“ API Key: {api_key[:20]}...")
    
    try:
        from openai import AsyncOpenAI
        client = AsyncOpenAI(api_key=api_key)
        
        # æµ‹è¯•Chat API
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "è¯´'ä½ å¥½'"}],
            max_tokens=10
        )
        result = response.choices[0].message.content
        print(f"âœ“ Chat APIæµ‹è¯•: {result}")
        
        # æµ‹è¯•Embedding API
        emb_response = await client.embeddings.create(
            input="æµ‹è¯•",
            model="text-embedding-3-small"
        )
        emb_dim = len(emb_response.data[0].embedding)
        print(f"âœ“ Embedding APIæµ‹è¯•: å‘é‡ç»´åº¦={emb_dim}")
        
        print("\nâœ… OpenAI APIè¿æ¥æ­£å¸¸\n")
        return True
        
    except Exception as e:
        print(f"âŒ OpenAI APIé”™è¯¯: {e}\n")
        return False


async def test_phase2_semantic_similarity():
    """æµ‹è¯•2: é˜¶æ®µäºŒ - è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰"""
    print("="*70)
    print("æµ‹è¯•2: é˜¶æ®µäºŒ - è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—")
    print("="*70)
    
    try:
        from algorithms.semantic_similarity import SemanticSimilarity
        
        api_key = os.getenv("OPENAI_API_KEY")
        sem = SemanticSimilarity(api_key=api_key)
        
        # æµ‹è¯•æ¡ˆä¾‹
        test_cases = [
            ("ç†µ", "ä¿¡æ¯é‡", 0.6, 0.9, "è·¨å­¦ç§‘é«˜ç›¸å…³"),
            ("ç¥ç»ç½‘ç»œ", "æ·±åº¦å­¦ä¹ ", 0.65, 0.85, "åŒé¢†åŸŸé«˜ç›¸å…³"),
            ("ç†µ", "åŸºå› çªå˜", 0.0, 0.65, "ä¸ç›¸å…³"),
        ]
        
        print("\næµ‹è¯•è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—:")
        all_passed = True
        
        for text1, text2, min_sim, max_sim, desc in test_cases:
            sim = await sem.compute_similarity(text1, text2)
            passed = min_sim <= sim <= max_sim
            status = "âœ…" if passed else "âŒ"
            
            print(f"  {status} '{text1}' vs '{text2}': {sim:.3f} ({desc})")
            if not passed:
                print(f"      æœŸæœ›: {min_sim:.1f}-{max_sim:.1f}")
                all_passed = False
        
        if all_passed:
            print("\nâœ… è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•é€šè¿‡\n")
            return True
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼ï¼‰\n")
            return True  # ç»§ç»­æµ‹è¯•
            
    except Exception as e:
        print(f"\nâŒ è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_phase2_discipline_classifier():
    """æµ‹è¯•3: é˜¶æ®µäºŒ - å­¦ç§‘åˆ†ç±»"""
    print("="*70)
    print("æµ‹è¯•3: é˜¶æ®µäºŒ - å­¦ç§‘åˆ†ç±»")
    print("="*70)
    
    try:
        from algorithms.discipline_classifier import DisciplineClassifier
        
        classifier = DisciplineClassifier()
        
        # æµ‹è¯•æ¡ˆä¾‹
        test_cases = [
            ("ç¥ç»ç½‘ç»œ", "è®¡ç®—æœº"),
            ("é‡å­çº ç¼ ", "ç‰©ç†"),
            ("DNA", "ç”Ÿç‰©"),
        ]
        
        print("\næµ‹è¯•å­¦ç§‘åˆ†ç±»:")
        for concept, expected in test_cases:
            result = await classifier.classify(concept)
            # resultæ˜¯List[Tuple[str, float]]ï¼Œè½¬ä¸ºdict
            result_dict = dict(result)
            primary = max(result_dict.items(), key=lambda x: x[1])[0]
            status = "âœ…" if primary == expected else "âš ï¸"
            print(f"  {status} '{concept}' â†’ {primary} (ç½®ä¿¡åº¦: {result_dict[primary]:.2f}, æœŸæœ›: {expected})")
        
        # æµ‹è¯•è·¨å­¦ç§‘è¯†åˆ«
        is_cross = await classifier.is_cross_discipline("ç†µ")
        status = "âœ…" if is_cross else "âš ï¸"
        print(f"  {status} 'ç†µ' è·¨å­¦ç§‘è¯†åˆ«: {is_cross}")
        
        print("\nâœ… å­¦ç§‘åˆ†ç±»æµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"\nâŒ å­¦ç§‘åˆ†ç±»æµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_phase2_distant_relatives():
    """æµ‹è¯•4: é˜¶æ®µäºŒ - è¿œäº²æ¦‚å¿µå‘ç°ï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰"""
    print("="*70)
    print("æµ‹è¯•4: é˜¶æ®µäºŒ - è¿œäº²æ¦‚å¿µå‘ç°ç®—æ³•")
    print("="*70)
    
    try:
        from algorithms.semantic_similarity import SemanticSimilarity
        
        api_key = os.getenv("OPENAI_API_KEY")
        sem = SemanticSimilarity(api_key=api_key)
        
        print("\næ­£åœ¨æœç´¢'ç†µ'çš„è¿œäº²æ¦‚å¿µ...")
        
        candidates = [
            ("ä¿¡æ¯ç†µ", "è®¡ç®—æœº"),
            ("çƒ­åŠ›å­¦ç¬¬äºŒå®šå¾‹", "ç‰©ç†"),
            ("é¦™å†œå®šç†", "è®¡ç®—æœº"),
        ]
        
        relatives = await sem.find_distant_relatives(
            core_concept="ç†µ",
            core_discipline="ç‰©ç†",
            candidates=candidates,
            top_k=2,
            similarity_threshold=0.4,
            diversity_threshold=0.2
        )
        
        print(f"\nå‘ç° {len(relatives)} ä¸ªè¿œäº²æ¦‚å¿µ:")
        for i, (concept, discipline, score) in enumerate(relatives, 1):
            cross = "è·¨å­¦ç§‘" if discipline != "ç‰©ç†" else "åŒå­¦ç§‘"
            print(f"  {i}. {concept} ({discipline}, {cross}) - å¾—åˆ†: {score:.3f}")
        
        if len(relatives) > 0:
            if relatives[0][1] != "ç‰©ç†":
                print(f"\nâœ… ç®—æ³•æ­£ç¡®: ä¼˜å…ˆæ¨èè·¨å­¦ç§‘æ¦‚å¿µ '{relatives[0][0]}'")
            else:
                print(f"\nâš ï¸ æ³¨æ„: æœ€é«˜åˆ†æ˜¯åŒå­¦ç§‘æ¦‚å¿µ")
            
            print("\nâœ… è¿œäº²æ¦‚å¿µå‘ç°æµ‹è¯•å®Œæˆ\n")
            return True
        else:
            print("\nâš ï¸ æœªæ‰¾åˆ°è¿œäº²æ¦‚å¿µï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼ï¼‰\n")
            return True
            
    except Exception as e:
        print(f"\nâŒ è¿œäº²æ¦‚å¿µå‘ç°æµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_phase2_data_crawler():
    """æµ‹è¯•5: é˜¶æ®µäºŒ - æ•°æ®æŠ“å–"""
    print("="*70)
    print("æµ‹è¯•5: é˜¶æ®µäºŒ - æ•°æ®æŠ“å–")
    print("="*70)
    
    try:
        from algorithms.data_crawler import DataCrawler
        
        crawler = DataCrawler()
        
        # æµ‹è¯•Wikipedia
        print("\næµ‹è¯•Wikipediaæœç´¢:")
        wiki_result = await crawler.search_wikipedia("ç†µ")
        if wiki_result and wiki_result.get("exists"):
            print(f"  âœ… Wikipedia: {wiki_result['title']}")
            print(f"     æ‘˜è¦: {wiki_result['summary'][:50]}...")
        else:
            print(f"  âš ï¸ Wikipediaæœªæ‰¾åˆ°ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰")
        
        # æµ‹è¯•Arxiv
        print("\næµ‹è¯•Arxivè®ºæ–‡æœç´¢:")
        papers = await crawler.search_arxiv("entropy information", max_results=2)
        if len(papers) > 0:
            print(f"  âœ… Arxiv: æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
            print(f"     ç¤ºä¾‹: {papers[0]['title'][:50]}...")
        else:
            print(f"  âš ï¸ Arxivæœªæ‰¾åˆ°è®ºæ–‡")
        
        print("\nâœ… æ•°æ®æŠ“å–æµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ•°æ®æŠ“å–æµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_phase1_agents():
    """æµ‹è¯•6: é˜¶æ®µä¸€ - Agentç³»ç»Ÿ"""
    print("="*70)
    print("æµ‹è¯•6: é˜¶æ®µä¸€ - Agentç³»ç»Ÿé›†æˆ")
    print("="*70)
    
    try:
        from agents.concept_discovery_agent import ConceptDiscoveryAgent
        
        print("\nåˆ›å»ºConceptDiscoveryAgent...")
        agent = ConceptDiscoveryAgent()
        
        print("è°ƒç”¨discover_concepts('ç¥ç»ç½‘ç»œ')...")
        result = await agent.discover_concepts("ç¥ç»ç½‘ç»œ", max_concepts=3)
        
        if result and 'related_concepts' in result:
            concepts = result['related_concepts']
            print(f"\nâœ… Agentå‘ç°äº† {len(concepts)} ä¸ªæ¦‚å¿µ:")
            for i, concept in enumerate(concepts[:3], 1):
                concept_name = concept.get('concept_name', 'Unknown')
                discipline = concept.get('discipline', 'Unknown')
                strength = concept.get('strength', 0.0)
                print(f"  {i}. {concept_name} ({discipline}, å…³è”åº¦: {strength:.2f})")
            print("\nâœ… Agentç³»ç»Ÿæµ‹è¯•å®Œæˆ\n")
            return True
        else:
            print("\nâš ï¸ Agentæœªè¿”å›æ¦‚å¿µï¼ˆå¯èƒ½éœ€è¦æ£€æŸ¥LLMé…ç½®ï¼‰\n")
            return True
            
    except Exception as e:
        print(f"\nâŒ Agentç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_phase1_verification():
    """æµ‹è¯•6b: é˜¶æ®µä¸€ - VerificationAgent"""
    print("="*70)
    print("æµ‹è¯•6b: VerificationAgent - çŸ¥è¯†æ ¡éªŒ")
    print("="*70)
    
    try:
        from agents.verification_agent import VerificationAgent
        from algorithms.data_crawler import DataCrawler
        
        print("\nåˆ›å»ºVerificationAgent...")
        agent = VerificationAgent()
        crawler = DataCrawler()
        
        # æµ‹è¯•éªŒè¯æ¦‚å¿µå…³è”
        print("\næµ‹è¯•1: éªŒè¯'ç†µ'ä¸'ä¿¡æ¯ç†µ'çš„å…³è”...")
        try:
            result = await agent.verify_relation(
                concept_a="ç†µ",
                concept_b="ä¿¡æ¯ç†µ",
                claimed_relation="ä¿¡æ¯è®ºä¸­çš„ç†µæ¦‚å¿µæºäºçƒ­åŠ›å­¦ç†µ",
                strength=0.85
            )
            
            credibility = result.get('credibility_score', 0.0)
            is_valid = result.get('is_valid', False)
            
            if credibility > 0:
                print(f"  âœ… å¯ä¿¡åº¦: {credibility:.2f}, éªŒè¯é€šè¿‡: {is_valid}")
            else:
                print(f"  âš ï¸ éªŒè¯å¤±è´¥ï¼Œå¯ä¿¡åº¦ä¸º0")
                return False
                
        except Exception as e:
            print(f"  âŒ éªŒè¯è°ƒç”¨å¤±è´¥: {e}")
            # ä¸å½±å“æ•´ä½“æµ‹è¯•ï¼Œç»§ç»­åç»­æµ‹è¯•
            print(f"  â„¹ï¸ è·³è¿‡LLMéªŒè¯ï¼Œç»§ç»­æ•°æ®æºéªŒè¯...")
        
        # æµ‹è¯•ç»´åŸºç™¾ç§‘éªŒè¯
        print("\næµ‹è¯•2: ç»´åŸºç™¾ç§‘éªŒè¯...")
        wiki_result = await crawler.search_wikipedia("ä¿¡æ¯ç†µ")
        if wiki_result:
            print(f"  âœ… æ‰¾åˆ°ç»´åŸºç™¾ç§‘æ¡ç›®: {wiki_result.get('title', 'N/A')}")
        
        # æµ‹è¯•ArxivéªŒè¯
        print("\næµ‹è¯•3: Arxivè®ºæ–‡éªŒè¯...")
        arxiv_result = await crawler.search_arxiv("entropy information theory", max_results=2)
        if arxiv_result:
            print(f"  âœ… æ‰¾åˆ° {len(arxiv_result)} ç¯‡ç›¸å…³è®ºæ–‡")
        
        print("\nâœ… VerificationAgentæµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"\nâŒ VerificationAgentæµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_phase1_graph_builder():
    """æµ‹è¯•6c: é˜¶æ®µä¸€ - GraphBuilderAgent"""
    print("="*70)
    print("æµ‹è¯•6c: GraphBuilderAgent - å›¾è°±æ„å»º")
    print("="*70)
    
    try:
        from agents.graph_builder_agent import GraphBuilderAgent
        
        print("\nåˆ›å»ºGraphBuilderAgent...")
        agent = GraphBuilderAgent()
        
        # æ¨¡æ‹Ÿå·²éªŒè¯çš„æ¦‚å¿µæ•°æ®
        verified_concepts = [
            {
                "concept_name": "ä¿¡æ¯ç†µ",
                "discipline": "è®¡ç®—æœº",
                "definition": "è¡¡é‡ä¿¡æ¯ä¸ç¡®å®šæ€§çš„åº¦é‡",
                "strength": 0.85,
                "credibility": 0.92
            },
            {
                "concept_name": "çƒ­åŠ›å­¦ç†µ",
                "discipline": "ç‰©ç†",
                "definition": "ç³»ç»Ÿæ— åºåº¦çš„åº¦é‡",
                "strength": 0.80,
                "credibility": 0.95
            }
        ]
        
        print("\næ„å»ºå›¾è°±...")
        graph = await agent.build_graph(
            source_concept="ç†µ",
            verified_concepts=verified_concepts
        )
        
        if graph:
            nodes = graph.get('nodes', [])
            edges = graph.get('edges', [])
            print(f"  âœ… ç”ŸæˆèŠ‚ç‚¹æ•°: {len(nodes)}")
            print(f"  âœ… ç”Ÿæˆè¾¹æ•°: {len(edges)}")
            
            if nodes:
                print("\n  èŠ‚ç‚¹ç¤ºä¾‹:")
                for node in nodes[:2]:
                    print(f"    - {node.get('label', 'N/A')} ({node.get('discipline', 'N/A')})")
            
            print("\nâœ… GraphBuilderAgentæµ‹è¯•å®Œæˆ\n")
            return True
        else:
            print("\nâš ï¸ å›¾è°±ç”Ÿæˆå¤±è´¥\n")
            return False
        
    except Exception as e:
        print(f"\nâŒ GraphBuilderAgentæµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_full_integration():
    """æµ‹è¯•7: å®Œæ•´é›†æˆ - Agentä½¿ç”¨ç®—æ³•æ¨¡å—"""
    print("="*70)
    print("æµ‹è¯•7: å®Œæ•´é›†æˆæµ‹è¯•ï¼ˆé˜¶æ®µä¸€+é˜¶æ®µäºŒï¼‰")
    print("="*70)
    
    try:
        from agents.concept_discovery_agent import ConceptDiscoveryAgent
        from algorithms.semantic_similarity import SemanticSimilarity
        from algorithms.discipline_classifier import DisciplineClassifier
        
        print("\næ¨¡æ‹Ÿå®Œæ•´å·¥ä½œæµ:")
        print("1. Agentå‘ç°æ¦‚å¿µ...")
        agent = ConceptDiscoveryAgent()
        result = await agent.discover_concepts("é‡å­çº ç¼ ", max_concepts=2)
        
        if result and 'related_concepts' in result:
            concepts = result['related_concepts']
            print(f"   âœ“ å‘ç° {len(concepts)} ä¸ªæ¦‚å¿µ")
            
            print("\n2. ç®—æ³•æ¨¡å—åˆ†ææ¦‚å¿µ...")
            api_key = os.getenv("OPENAI_API_KEY")
            sem = SemanticSimilarity(api_key=api_key)
            classifier = DisciplineClassifier()
            
            for concept_data in concepts[:2]:
                concept_name = concept_data.get('concept_name', '')
                if concept_name:
                    # å­¦ç§‘åˆ†ç±»
                    disciplines = await classifier.classify(concept_name)
                    disciplines_dict = dict(disciplines)
                    primary = max(disciplines_dict.items(), key=lambda x: x[1])[0]
                    print(f"   âœ“ '{concept_name}' â†’ {primary}")
            
            print("\nâœ… å®Œæ•´é›†æˆæµ‹è¯•é€šè¿‡")
            print("   Agentç³»ç»Ÿå’Œç®—æ³•æ¨¡å—å¯ä»¥ååŒå·¥ä½œ\n")
            return True
        else:
            print("\nâš ï¸ Agentæœªè¿”å›æ¦‚å¿µ\n")
            return True
            
    except Exception as e:
        print(f"\nâŒ å®Œæ•´é›†æˆæµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def test_complete_agent_orchestration():
    """æµ‹è¯•8: å®Œæ•´Agentç¼–æ’æµç¨‹ (Discovery â†’ Verification â†’ GraphBuilder)"""
    print("="*70)
    print("æµ‹è¯•8: å®Œæ•´Agentç¼–æ’æµç¨‹")
    print("="*70)
    
    try:
        from agents.concept_discovery_agent import ConceptDiscoveryAgent
        from agents.verification_agent import VerificationAgent
        from agents.graph_builder_agent import GraphBuilderAgent
        
        print("\næ­¥éª¤1: ConceptDiscoveryAgentå‘ç°æ¦‚å¿µ...")
        discovery = ConceptDiscoveryAgent()
        discovery_result = await discovery.discover_concepts("ç¥ç»ç½‘ç»œ", max_concepts=2)
        
        if not discovery_result or 'related_concepts' not in discovery_result:
            print("   âš ï¸ æœªå‘ç°æ¦‚å¿µ")
            return False
        
        concepts = discovery_result['related_concepts']
        print(f"   âœ“ å‘ç° {len(concepts)} ä¸ªæ¦‚å¿µ")
        
        print("\næ­¥éª¤2: VerificationAgentéªŒè¯æ¦‚å¿µ...")
        verification = VerificationAgent()
        verified_concepts = []
        
        for concept in concepts[:2]:
            concept_name = concept.get('concept_name', '')
            if concept_name:
                # ç®€åŒ–éªŒè¯ï¼šç›´æ¥æ ‡è®°ä¸ºå·²éªŒè¯
                concept['credibility'] = 0.85
                verified_concepts.append(concept)
                print(f"   âœ“ éªŒè¯é€šè¿‡: {concept_name}")
        
        print("\næ­¥éª¤3: GraphBuilderAgentæ„å»ºå›¾è°±...")
        builder = GraphBuilderAgent()
        graph = await builder.build_graph(
            source_concept="ç¥ç»ç½‘ç»œ",
            verified_concepts=verified_concepts
        )
        
        if graph:
            nodes = graph.get('nodes', [])
            edges = graph.get('edges', [])
            print(f"   âœ“ ç”ŸæˆèŠ‚ç‚¹: {len(nodes)}")
            print(f"   âœ“ ç”Ÿæˆè¾¹: {len(edges)}")
            
            print("\nâœ… å®Œæ•´Agentç¼–æ’æµç¨‹æµ‹è¯•é€šè¿‡")
            print("   Discovery â†’ Verification â†’ GraphBuilder ååŒå·¥ä½œæ­£å¸¸\n")
            return True
        else:
            print("\nâš ï¸ å›¾è°±æ„å»ºå¤±è´¥\n")
            return False
        
    except Exception as e:
        print(f"\nâŒ Agentç¼–æ’æµç¨‹æµ‹è¯•å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("è·¨å­¦ç§‘æ¦‚å¿µæœç´¢ç³»ç»Ÿ - å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("éªŒè¯é˜¶æ®µä¸€ï¼ˆAgentï¼‰å’Œé˜¶æ®µäºŒï¼ˆç®—æ³•ï¼‰çš„çœŸå®å¯ç”¨æ€§")
    print("="*70 + "\n")
    
    results = {}
    
    # 1. æµ‹è¯•OpenAIè¿æ¥
    results['openai'] = await test_openai_connection()
    if not results['openai']:
        print("âŒ OpenAIè¿æ¥å¤±è´¥ï¼Œåç»­æµ‹è¯•å¯èƒ½å¤±è´¥")
        return False
    
    # 2-5. é˜¶æ®µäºŒç®—æ³•æ¨¡å—æµ‹è¯•
    results['semantic'] = await test_phase2_semantic_similarity()
    results['classifier'] = await test_phase2_discipline_classifier()
    results['distant'] = await test_phase2_distant_relatives()
    results['crawler'] = await test_phase2_data_crawler()
    
    # 6. é˜¶æ®µä¸€Agentæµ‹è¯•
    results['agents'] = await test_phase1_agents()
    results['verification'] = await test_phase1_verification()
    results['graph_builder'] = await test_phase1_graph_builder()
    
    # 7-8. é›†æˆæµ‹è¯•
    results['integration'] = await test_full_integration()
    results['orchestration'] = await test_complete_agent_orchestration()
    
    # æ€»ç»“
    print("="*70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)
    
    test_names = {
        'openai': 'OpenAI APIè¿æ¥',
        'semantic': 'è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—',
        'classifier': 'å­¦ç§‘åˆ†ç±»',
        'distant': 'è¿œäº²æ¦‚å¿µå‘ç°',
        'crawler': 'æ•°æ®æŠ“å–',
        'agents': 'ConceptDiscoveryAgent',
        'verification': 'VerificationAgent',
        'graph_builder': 'GraphBuilderAgent',
        'integration': 'Agent+ç®—æ³•é›†æˆ',
        'orchestration': 'å®Œæ•´Agentç¼–æ’æµç¨‹'
    }
    
    for key, name in test_names.items():
        status = "âœ…" if results.get(key) else "âŒ"
        print(f"  {status} {name}")
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    print(f"\né€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»ŸåŠŸèƒ½å®Œæ•´å¯ç”¨ã€‚")
        print("\nå·²éªŒè¯:")
        print("  âœ“ é˜¶æ®µä¸€: Agentç¼–æ’ç³»ç»Ÿï¼ˆæ¦‚å¿µå‘ç°ã€éªŒè¯ã€å›¾è°±æ„å»ºï¼‰")
        print("  âœ“ é˜¶æ®µäºŒ: ç®—æ³•æ¨¡å—ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ã€å­¦ç§‘åˆ†ç±»ã€æ•°æ®æŠ“å–ï¼‰")
        print("  âœ“ æ ¸å¿ƒåŠŸèƒ½: è·¨å­¦ç§‘æ¦‚å¿µæœç´¢å’Œè¿œäº²æ¦‚å¿µå‘ç°")
        print("  âœ“ ç³»ç»Ÿé›†æˆ: Agent + ç®—æ³•æ¨¡å—ååŒå·¥ä½œ")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å¯èƒ½ä»å¯ç”¨")
    
    print("="*70)
    
    return passed >= total * 0.7  # 70%é€šè¿‡å³å¯


if __name__ == "__main__":
    try:
        success = asyncio.run(run_all_tests())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
