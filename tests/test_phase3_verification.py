"""
ç¬¬ä¸‰éƒ¨åˆ†æµ‹è¯•ï¼šçŸ¥è¯†æ ¡éªŒå±‚
æµ‹è¯•å¤šæºéªŒè¯ã€å¯ä¿¡åº¦è¯„åˆ†ã€å†²çªæ£€æµ‹å’Œæ¥æºæº¯æº
"""

import os
import sys
import asyncio
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.WARNING,
    format='%(message)s'
)
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from algorithms.credibility_scorer import (
    CredibilityScorer, 
    MultiSourceVerifier,
    Evidence, 
    SourceType,
    CredibilityLevel,
    ConflictInfo
)
from agents.verification_agent import VerificationAgent


def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"{title}")
    print('='*60)


def print_result(success: bool, message: str):
    """æ‰“å°æµ‹è¯•ç»“æœï¼ˆä¿®å¤ç¼–ç é—®é¢˜ï¼‰"""
    symbol = "[PASS]" if success else "[FAIL]"
    print(f"  {symbol} {message}")


async def test_credibility_scorer():
    """æµ‹è¯•1: å¯ä¿¡åº¦è¯„åˆ†ç®—æ³•"""
    print_section("æµ‹è¯•1: å¯ä¿¡åº¦è¯„åˆ†ç®—æ³•")
    
    try:
        scorer = CredibilityScorer(
            min_evidence_count=2,
            wikipedia_weight=0.7,
            arxiv_weight=0.9,
            llm_weight=0.3,  # é™ä½LLMæƒé‡
            semantic_conflict_threshold=0.75
        )
        
        # åˆ›å»ºå¤šä¸ªè¯æ®
        evidences = [
            Evidence(
                source_type=SourceType.WIKIPEDIA,
                source_name="Wikipedia",
                content="ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§è®¡ç®—æ¨¡å‹ï¼Œå—ç”Ÿç‰©ç¥ç»ç³»ç»Ÿå¯å‘",
                url="https://zh.wikipedia.org/wiki/ç¥ç»ç½‘ç»œ",
                confidence=0.8
            ),
            Evidence(
                source_type=SourceType.ARXIV,
                source_name="Arxiv Paper",
                content="Artificial neural networks are inspired by biological neural networks",
                url="https://arxiv.org/abs/1234.5678",
                confidence=0.9
            ),
            Evidence(
                source_type=SourceType.LLM_REASONING,
                source_name="LLM Analysis",
                content="ç¥ç»ç½‘ç»œçš„ç»“æ„å’ŒåŠŸèƒ½ä¸ç”Ÿç‰©ç¥ç»å…ƒç½‘ç»œé«˜åº¦ç›¸ä¼¼",
                confidence=0.7
            )
        ]
        
        # è®¡ç®—å¯ä¿¡åº¦
        result = scorer.calculate_credibility(
            evidences, "ç¥ç»ç½‘ç»œ", "ç”Ÿç‰©ç¥ç»ç³»ç»Ÿ"
        )
        
        print(f"\n  æ¦‚å¿µå¯¹: ç¥ç»ç½‘ç»œ <-> ç”Ÿç‰©ç¥ç»ç³»ç»Ÿ")
        print(f"  è¯æ®æ•°é‡: {result['evidence_count']}")
        print(f"  å¯ä¿¡åº¦åˆ†æ•°: {result['credibility_score']:.3f}")
        print(f"  å¯ä¿¡åº¦ç­‰çº§: {result['credibility_level']}")
        print(f"  æ¥æºå¤šæ ·æ€§: {result['source_diversity']:.3f}")
        print(f"  æ˜¯å¦æœ‰å†²çª: {result['has_conflicts']}")
        
        # éªŒè¯ç»“æœ
        success = (
            result['evidence_count'] == 3 and
            result['credibility_score'] >= 0.7 and
            result['credibility_level'] in ['reliable', 'verified']
        )
        
        print_result(success, "å¯ä¿¡åº¦è¯„åˆ†ç®—æ³•æ­£å¸¸å·¥ä½œ")
        
        return success
        
    except Exception as e:
        print_result(False, f"å¯ä¿¡åº¦è¯„åˆ†æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_conflict_detection():
    """æµ‹è¯•2: å†²çªæ£€æµ‹(æ”¹è¿›ç‰ˆ:å«è¯­ä¹‰å†²çª)"""
    print_section("æµ‹è¯•2: å†²çªæ£€æµ‹ï¼ˆå¢å¼ºç‰ˆï¼‰")
    
    try:
        scorer = CredibilityScorer(
            llm_weight=0.3,
            semantic_conflict_threshold=0.75
        )
        
        # åˆ›å»ºå†²çªçš„è¯æ®ï¼ˆè¯­ä¹‰çŸ›ç›¾ï¼‰
        conflicting_evidences = [
            Evidence(
                source_type=SourceType.WIKIPEDIA,
                source_name="Wikipedia Source 1",
                content="é‡å­çº ç¼ ä¸èƒ½ç”¨äºè¶…å…‰é€Ÿé€šä¿¡ï¼Œè¿™æ˜¯å› ä¸ºæµ‹é‡ç»“æœæ˜¯éšæœºçš„",
                confidence=0.9
            ),
            Evidence(
                source_type=SourceType.LLM_REASONING,
                source_name="LLM Source",
                content="é‡å­çº ç¼ å¯ä»¥ç”¨äºä¿¡æ¯ä¼ è¾“ï¼Œé€šè¿‡çº ç¼ æ€å®ç°é€šä¿¡",
                confidence=0.4
            )
        ]
        
        result = scorer.calculate_credibility(
            conflicting_evidences, "é‡å­çº ç¼ ", "è¶…å…‰é€Ÿé€šä¿¡"
        )
        
        print(f"\n  æ¦‚å¿µå¯¹: é‡å­çº ç¼  <-> è¶…å…‰é€Ÿé€šä¿¡")
        print(f"  æ£€æµ‹åˆ°å†²çª: {result['has_conflicts']}")
        print(f"  å†²çªæ•°é‡: {len(result['conflicts'])}")
        
        if result['conflicts']:
            for i, conflict in enumerate(result['conflicts']):
                print(f"\n  å†²çª {i+1}:")
                print(f"    ç±»å‹: {conflict['conflict_type']}")
                print(f"    ä¸¥é‡ç¨‹åº¦: {conflict['severity']:.3f}")
                
                # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°è¯­ä¹‰å†²çª
                if conflict['conflict_type'] == 'semantic_contradiction':
                    print(f"    [NEW] è¯­ä¹‰çŸ›ç›¾æ£€æµ‹æˆåŠŸ!")
        
        # æµ‹è¯•å†²çªè§£å†³
        if result['conflicts']:
            conflicts_obj = [
                ConflictInfo(
                    conflicting_evidences=conflicting_evidences,
                    conflict_type=result['conflicts'][0]['conflict_type'],
                    severity=result['conflicts'][0]['severity']
                )
            ]
            resolved = scorer.resolve_conflicts(conflicts_obj, strategy="highest_confidence")
            
            print(f"\n  å†²çªè§£å†³ç­–ç•¥: highest_confidence")
            print(f"  è§£å†³åä¿ç•™è¯æ®æ•°: {len(resolved)}")
            if resolved:
                print(f"  é€‰æ‹©çš„è¯æ®: {resolved[0].source_name} (ç½®ä¿¡åº¦: {resolved[0].confidence})")
        
        # éªŒè¯æ˜¯å¦æ£€æµ‹åˆ°å†²çª
        success = result['has_conflicts'] and len(result['conflicts']) > 0
        print_result(success, "å†²çªæ£€æµ‹æœºåˆ¶æ­£å¸¸å·¥ä½œï¼ˆåŒ…æ‹¬è¯­ä¹‰å†²çªï¼‰")
        
        return success
        
    except Exception as e:
        print_result(False, f"å†²çªæ£€æµ‹æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_source_tracing():
    """æµ‹è¯•3: æ¥æºæº¯æº(æ”¹è¿›ç‰ˆ:å«å¼•ç”¨éªŒè¯)"""
    print_section("æµ‹è¯•3: æ¥æºæº¯æºä¸å¼•ç”¨éªŒè¯")
    
    try:
        scorer = CredibilityScorer(llm_weight=0.3)
        
        # æµ‹è¯•1: æœ‰æ•ˆçš„Arxivå¼•ç”¨
        print("\n  æµ‹è¯•1: æœ‰æ•ˆArxivå¼•ç”¨")
        evidence_valid = Evidence(
            source_type=SourceType.ARXIV,
            source_name="Nature Physics",
            content="Quantum entanglement research (arxiv.org/abs/2301.12345) shows that...",
            url="https://arxiv.org/abs/2301.12345",
            confidence=0.95,
            timestamp="2024-01-15"
        )
        
        trace_info = scorer.trace_source(evidence_valid)
        
        print(f"  åŸå§‹æ¥æº: {trace_info['primary_source']['name']}")
        print(f"  æ¥æºç±»å‹: {trace_info['primary_source']['type']}")
        print(f"  æ¥æºæƒå¨åº¦: {trace_info['reliability_factors']['source_authority']:.2f}")
        print(f"  [NEW] å¼•ç”¨éªŒè¯: {trace_info['reliability_factors']['citation_verified']}")
        
        if 'citation_check' in trace_info:
            citation_check = trace_info['citation_check']
            print(f"  [NEW] å¼•ç”¨è¯¦æƒ…:")
            print(f"    - å‘ç°å¼•ç”¨æ•°: {len(citation_check['citations_found'])}")
            print(f"    - éªŒè¯é€šè¿‡: {len(citation_check['verified_citations'])}")
            print(f"    - æ— æ•ˆå¼•ç”¨: {len(citation_check['invalid_citations'])}")
            if citation_check['verified_citations']:
                print(f"    - ç¤ºä¾‹: {citation_check['verified_citations'][0]}")
        
        # æµ‹è¯•2: LLMè¯æ®æ— å¼•ç”¨ï¼ˆé¢„è­¦ï¼‰
        print("\n  æµ‹è¯•2: LLMè¯æ®æ— å¼•ç”¨ï¼ˆåº”è¢«æ ‡è®°ï¼‰")
        evidence_llm = Evidence(
            source_type=SourceType.LLM_REASONING,
            source_name="LLM Analysis",
            content="æ ¹æ®2023å¹´çš„ç ”ç©¶ï¼Œé‡å­çº ç¼ é€Ÿåº¦è¾¾åˆ°10^8å€å…‰é€Ÿ",  # ç¼–é€ çš„ä¿¡æ¯ï¼Œæ— å¼•ç”¨
            confidence=0.6
        )
        
        trace_info_llm = scorer.trace_source(evidence_llm)
        print(f"  [NEW] å¼•ç”¨éªŒè¯: {trace_info_llm['reliability_factors']['citation_verified']}")
        print(f"  [NEW] è­¦å‘Š: LLMè¯æ®æ— å¯éªŒè¯å¼•ç”¨ï¼Œå¯ä¿¡åº¦é™ä½")
        
        # æµ‹è¯•3: æ— æ•ˆArxiv ID
        print("\n  æµ‹è¯•3: æ— æ•ˆArxivå¼•ç”¨")
        evidence_invalid = Evidence(
            source_type=SourceType.LLM_REASONING,
            source_name="Fake Source",
            content="According to arxiv.org/abs/9999.99999 (invalid format)...",
            confidence=0.7
        )
        
        trace_info_invalid = scorer.trace_source(evidence_invalid)
        citation_check_invalid = trace_info_invalid['citation_check']
        print(f"  [NEW] å¼•ç”¨éªŒè¯: {trace_info_invalid['reliability_factors']['citation_verified']}")
        if citation_check_invalid['invalid_citations']:
            print(f"  [NEW] æ— æ•ˆå¼•ç”¨: {citation_check_invalid['invalid_citations']}")
        
        success = (
            trace_info['reliability_factors']['citation_verified'] and
            not trace_info_llm['reliability_factors']['citation_verified'] and
            not trace_info_invalid['reliability_factors']['citation_verified']
        )
        
        print_result(success, "æ¥æºæº¯æºå’Œå¼•ç”¨éªŒè¯åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        
        return success
        
    except Exception as e:
        print_result(False, f"æ¥æºæº¯æºæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_multi_source_verifier():
    """æµ‹è¯•4: å¤šæºéªŒè¯å™¨"""
    print_section("æµ‹è¯•4: å¤šæºéªŒè¯å™¨")
    
    try:
        verifier = MultiSourceVerifier()
        
        # æ¨¡æ‹Ÿå¤šä¸ªæ•°æ®æº
        data_sources = {
            "wikipedia": {
                "summary": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ",
                "url": "https://zh.wikipedia.org/wiki/æ·±åº¦å­¦ä¹ ",
                "timestamp": "2024-01-15"
            },
            "arxiv": {
                "abstract": "Deep learning is a subset of machine learning based on artificial neural networks",
                "pdf_url": "https://arxiv.org/abs/1234.5678",
                "published": "2023-12-01"
            },
            "llm_reasoning": {
                "reasoning": "æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œæ˜¯å¯†åˆ‡ç›¸å…³çš„æ¦‚å¿µï¼Œæ·±åº¦å­¦ä¹ æ­£æ˜¯ä½¿ç”¨æ·±å±‚ç¥ç»ç½‘ç»œå®ç°çš„",
                "confidence": 0.85
            }
        }
        
        # æ‰§è¡Œå¤šæºéªŒè¯
        result = await verifier.verify_from_multiple_sources(
            "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", data_sources
        )
        
        print(f"\n  æ¦‚å¿µå¯¹: æ·±åº¦å­¦ä¹  <-> ç¥ç»ç½‘ç»œ")
        print(f"  æ•°æ®æºæ•°é‡: {len(data_sources)}")
        print(f"  è¯æ®æ•°é‡: {result['evidence_count']}")
        print(f"  å¯ä¿¡åº¦åˆ†æ•°: {result['credibility_score']:.3f}")
        print(f"  å¯ä¿¡åº¦ç­‰çº§: {result['credibility_level']}")
        print(f"  æ¥æºå¤šæ ·æ€§: {result['source_diversity']:.3f}")
        
        print(f"\n  è¯æ®æ¥æº:")
        for i, evidence in enumerate(result['evidences'], 1):
            print(f"    {i}. {evidence['source_name']} (ç½®ä¿¡åº¦: {evidence['confidence']:.2f})")
        
        success = (
            result['evidence_count'] >= 2 and
            result['credibility_score'] >= 0.6
        )
        
        print_result(success, "å¤šæºéªŒè¯å™¨æ­£å¸¸å·¥ä½œ")
        
        return success
        
    except Exception as e:
        print_result(False, f"å¤šæºéªŒè¯å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_verification_agent_integration():
    """æµ‹è¯•5: VerificationAgenté›†æˆæµ‹è¯•"""
    print_section("æµ‹è¯•5: VerificationAgentå¤šæºéªŒè¯é›†æˆ")
    
    try:
        # æ£€æŸ¥APIå¯†é’¥
        if not os.getenv("OPENROUTER_API_KEY"):
            print_result(False, "æœªè®¾ç½®OPENROUTER_API_KEYï¼Œè·³è¿‡é›†æˆæµ‹è¯•")
            return False
        
        if not os.getenv("OPENAI_API_KEY"):
            print_result(False, "æœªè®¾ç½®OPENAI_API_KEYï¼Œè·³è¿‡é›†æˆæµ‹è¯•")
            return False
        
        agent = VerificationAgent()
        
        print(f"\n  æµ‹è¯•: ä½¿ç”¨å¤šæºéªŒè¯æ¨¡å¼")
        
        # æµ‹è¯•å¤šæºéªŒè¯
        result = await agent.verify_relation(
            concept_a="ç†µ",
            concept_b="ä¿¡æ¯ç†µ",
            claimed_relation="ä¿¡æ¯ç†µæ˜¯ç†µçš„æ¦‚å¿µåœ¨ä¿¡æ¯è®ºä¸­çš„åº”ç”¨",
            strength=0.9,
            enable_multi_source=True
        )
        
        print(f"\n  æ¦‚å¿µå¯¹: ç†µ <-> ä¿¡æ¯ç†µ")
        print(f"  éªŒè¯æ¨¡å¼: å¤šæºéªŒè¯")
        print(f"  å¯ä¿¡åº¦åˆ†æ•°: {result['credibility_score']:.3f}")
        print(f"  æ˜¯å¦é€šè¿‡: {result['is_valid']}")
        
        if 'evidence_count' in result:
            print(f"  è¯æ®æ•°é‡: {result['evidence_count']}")
        if 'source_diversity' in result:
            print(f"  æ¥æºå¤šæ ·æ€§: {result['source_diversity']:.3f}")
        if 'credibility_level' in result:
            print(f"  å¯ä¿¡åº¦ç­‰çº§: {result['credibility_level']}")
        
        if result.get('warnings'):
            print(f"\n  è­¦å‘Šä¿¡æ¯:")
            for warning in result['warnings']:
                print(f"    - {warning}")
        
        success = result['is_valid'] and result['credibility_score'] >= 0.5
        
        print_result(success, "VerificationAgentå¤šæºéªŒè¯é›†æˆæ­£å¸¸")
        
        return success
        
    except Exception as e:
        print_result(False, f"é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_evidence_quality_levels():
    """æµ‹è¯•6: ä¸åŒè´¨é‡çº§åˆ«çš„è¯æ®"""
    print_section("æµ‹è¯•6: è¯æ®è´¨é‡ç­‰çº§æµ‹è¯•")
    
    try:
        scorer = CredibilityScorer()
        
        # æµ‹è¯•ä¸åŒè´¨é‡çº§åˆ«
        test_cases = [
            {
                "name": "é«˜è´¨é‡è¯æ®ï¼ˆå¤šæº+é«˜ç½®ä¿¡åº¦ï¼‰",
                "evidences": [
                    Evidence(SourceType.ARXIV, "Arxiv", "High quality paper", confidence=0.95),
                    Evidence(SourceType.WIKIPEDIA, "Wikipedia", "Verified info", confidence=0.85),
                    Evidence(SourceType.TEXTBOOK, "Textbook", "Standard definition", confidence=0.9)
                ],
                "expected_level": CredibilityLevel.VERIFIED
            },
            {
                "name": "ä¸­ç­‰è´¨é‡è¯æ®ï¼ˆå•æº+ä¸­ç­‰ç½®ä¿¡åº¦ï¼‰",
                "evidences": [
                    Evidence(SourceType.WIKIPEDIA, "Wikipedia", "Some info", confidence=0.6),
                    Evidence(SourceType.LLM_REASONING, "LLM", "Reasoning", confidence=0.5)
                ],
                "expected_level": CredibilityLevel.PROBABLE
            },
            {
                "name": "ä½è´¨é‡è¯æ®ï¼ˆå•æº+ä½ç½®ä¿¡åº¦ï¼‰",
                "evidences": [
                    Evidence(SourceType.LLM_REASONING, "LLM", "Uncertain", confidence=0.3)
                ],
                "expected_level": CredibilityLevel.QUESTIONABLE
            }
        ]
        
        all_passed = True
        
        for i, test_case in enumerate(test_cases, 1):
            result = scorer.calculate_credibility(
                test_case["evidences"], "æ¦‚å¿µA", "æ¦‚å¿µB"
            )
            
            print(f"\n  æµ‹è¯• {i}: {test_case['name']}")
            print(f"    å¯ä¿¡åº¦åˆ†æ•°: {result['credibility_score']:.3f}")
            print(f"    å¯ä¿¡åº¦ç­‰çº§: {result['credibility_level']}")
            print(f"    é¢„æœŸç­‰çº§: {test_case['expected_level'].value}")
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆé¢„æœŸç­‰çº§èŒƒå›´
            level_match = result['credibility_level'] == test_case['expected_level'].value
            
            if not level_match:
                # å…è®¸ç›¸é‚»ç­‰çº§ï¼ˆå› ä¸ºè¾¹ç•Œå€¼å¯èƒ½ä¸åŒï¼‰
                levels_order = ['questionable', 'uncertain', 'probable', 'reliable', 'verified']
                actual_idx = levels_order.index(result['credibility_level'])
                expected_idx = levels_order.index(test_case['expected_level'].value)
                level_match = abs(actual_idx - expected_idx) <= 1
            
            passed = level_match
            all_passed = all_passed and passed
            
            print_result(passed, f"ç­‰çº§åˆ¤å®š{'æ­£ç¡®' if passed else 'ä¸ç¬¦'}")
        
        print_result(all_passed, "è¯æ®è´¨é‡ç­‰çº§æµ‹è¯•å®Œæˆ")
        
        return all_passed
        
    except Exception as e:
        print_result(False, f"è¯æ®è´¨é‡æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šçŸ¥è¯†æ ¡éªŒå±‚ - åŠŸèƒ½æµ‹è¯•")
    print("æµ‹è¯•å¤šæºéªŒè¯ã€å¯ä¿¡åº¦è¯„åˆ†ã€å†²çªæ£€æµ‹å’Œæ¥æºæº¯æº")
    print("="*60)
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(await test_credibility_scorer())
    results.append(await test_conflict_detection())
    results.append(await test_source_tracing())
    results.append(await test_multi_source_verifier())
    results.append(await test_evidence_quality_levels())
    results.append(await test_verification_agent_integration())
    
    # æ±‡æ€»ç»“æœ
    print_section("æµ‹è¯•ç»“æœæ±‡æ€»")
    
    test_names = [
        "å¯ä¿¡åº¦è¯„åˆ†ç®—æ³•",
        "å†²çªæ£€æµ‹æœºåˆ¶",
        "æ¥æºæº¯æºåŠŸèƒ½",
        "å¤šæºéªŒè¯å™¨",
        "è¯æ®è´¨é‡ç­‰çº§",
        "VerificationAgenté›†æˆ"
    ]
    
    for i, (name, passed) in enumerate(zip(test_names, results), 1):
        print_result(passed, f"æµ‹è¯•{i}: {name}")
    
    passed_count = sum(results)
    total_count = len(results)
    
    print(f"\né€šè¿‡: {passed_count}/{total_count}")
    
    if passed_count == total_count:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¬¬ä¸‰éƒ¨åˆ†åŠŸèƒ½å®Œæ•´å¯ç”¨ã€‚")
        print("\nå·²éªŒè¯:")
        print("  âœ“ å¯ä¿¡åº¦è¯„åˆ†ç®—æ³•ï¼šåŸºäºå¤šè¯æ®åŠ æƒè®¡ç®—")
        print("  âœ“ å¤šæºéªŒè¯ï¼šæ•´åˆWikipediaã€Arxivã€LLM")
        print("  âœ“ å†²çªæ£€æµ‹ï¼šè¯†åˆ«è¯æ®çŸ›ç›¾å¹¶ä»²è£")
        print("  âœ“ æ¥æºæº¯æºï¼šè¿½è¸ªä¿¡æ¯æ¥æºé“¾")
        print("  âœ“ VerificationAgentï¼šå®Œæ•´é›†æˆå¤šæºéªŒè¯")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ ({total_count - passed_count} ä¸ª)")
    
    print("="*60)


if __name__ == "__main__":
    asyncio.run(main())
