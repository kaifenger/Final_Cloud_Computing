"""
é˜¶æ®µäºŒç®—æ³•æ¨¡å—æœ€ç»ˆæµ‹è¯•
ä½¿ç”¨æœ‰é¢åº¦çš„OpenRouterè´¦æˆ·ï¼Œé€‰æ‹©æœ€ä¼˜æ€§ä»·æ¯”æ¨¡å‹
"""
import asyncio
import os
from algorithms.semantic_similarity import SemanticSimilarity
from algorithms.discipline_classifier import DisciplineClassifier
from algorithms.data_crawler import DataCrawler


async def test_phase2_algorithms():
    """æµ‹è¯•é˜¶æ®µäºŒç®—æ³•æ¨¡å—"""
    
    print("="*70)
    print("é˜¶æ®µäºŒç®—æ³•æ¨¡å—æœ€ç»ˆæµ‹è¯•")
    print("="*70)
    
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("\nâŒ é”™è¯¯: OPENROUTER_API_KEY æœªè®¾ç½®")
        return False
    
    print(f"\nâœ“ API Key: {api_key[:20]}...")
    
    # æµ‹è¯•1: è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
    print("\n" + "="*70)
    print("æµ‹è¯•1: è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆLLMåˆ¤æ–­ï¼‰")
    print("="*70)
    
    sem = SemanticSimilarity(api_key=api_key)
    
    test_pairs = [
        ("ç†µ", "ä¿¡æ¯é‡", 0.5, 1.0),  # è·¨å­¦ç§‘é«˜ç›¸å…³
        ("ç¥ç»ç½‘ç»œ", "æ·±åº¦å­¦ä¹ ", 0.7, 1.0),  # åŒé¢†åŸŸé«˜ç›¸å…³
        ("ç†µ", "åŸºå› çªå˜", 0.0, 0.4),  # ä¸ç›¸å…³
    ]
    
    print("\næ­£åœ¨æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼åº¦...")
    all_passed = True
    
    for text1, text2, min_sim, max_sim in test_pairs:
        sim = await sem.compute_similarity(text1, text2)
        status = "âœ…" if min_sim <= sim <= max_sim else "âŒ"
        print(f"  {status} '{text1}' vs '{text2}': {sim:.3f} (æœŸæœ›: {min_sim:.1f}-{max_sim:.1f})")
        if not (min_sim <= sim <= max_sim):
            all_passed = False
    
    if not all_passed:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œä½†è¿™å¯èƒ½æ˜¯é˜ˆå€¼è®¾ç½®é—®é¢˜")
    
    # æµ‹è¯•2: å­¦ç§‘åˆ†ç±»
    print("\n" + "="*70)
    print("æµ‹è¯•2: å­¦ç§‘åˆ†ç±»")
    print("="*70)
    
    classifier = DisciplineClassifier()
    
    test_cases = [
        ("ç¥ç»ç½‘ç»œ", "è®¡ç®—æœº"),
        ("ç†µ", None),  # è·¨å­¦ç§‘æ¦‚å¿µ
    ]
    
    for concept, expected_discipline in test_cases:
        result = await classifier.classify(concept)
        primary = max(result.items(), key=lambda x: x[1])[0]
        
        if expected_discipline:
            status = "âœ…" if primary == expected_discipline else "âŒ"
            print(f"  {status} '{concept}' â†’ {primary} (æœŸæœ›: {expected_discipline})")
        else:
            is_cross = classifier.is_cross_discipline(result)
            status = "âœ…" if is_cross else "âš ï¸"
            print(f"  {status} '{concept}' â†’ è·¨å­¦ç§‘: {is_cross}")
    
    # æµ‹è¯•3: è¿œäº²æ¦‚å¿µå‘ç°ï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰
    print("\n" + "="*70)
    print("æµ‹è¯•3: è¿œäº²æ¦‚å¿µå‘ç°ç®—æ³•")
    print("="*70)
    
    print("\næ­£åœ¨æœç´¢'ç†µ'çš„è¿œäº²æ¦‚å¿µï¼ˆéœ€30-60ç§’ï¼‰...")
    
    candidates = [
        ("ä¿¡æ¯ç†µ", "è®¡ç®—æœº"),
        ("çƒ­åŠ›å­¦ç¬¬äºŒå®šå¾‹", "ç‰©ç†"),
        ("é¦™å†œå®šç†", "è®¡ç®—æœº"),
    ]
    
    relatives = await sem.find_distant_relatives(
        core_concept="ç†µ",
        core_discipline="ç‰©ç†",
        candidates=candidates,
        top_k=2,
        similarity_threshold=0.4,
        diversity_threshold=0.2
    )
    
    print(f"\nå‘ç° {len(relatives)} ä¸ªè¿œäº²æ¦‚å¿µ:")
    for i, (concept, discipline, score) in enumerate(relatives, 1):
        cross_label = "è·¨å­¦ç§‘" if discipline != "ç‰©ç†" else "åŒå­¦ç§‘"
        print(f"  {i}. {concept} ({discipline}, {cross_label}) - å¾—åˆ†: {score:.3f}")
    
    if len(relatives) > 0 and relatives[0][1] != "ç‰©ç†":
        print(f"\n  âœ… ç®—æ³•æ­£ç¡®: ä¼˜å…ˆæ¨èè·¨å­¦ç§‘æ¦‚å¿µ '{relatives[0][0]}'")
    elif len(relatives) > 0:
        print(f"\n  âš ï¸ æ³¨æ„: æœ€é«˜åˆ†æ˜¯åŒå­¦ç§‘æ¦‚å¿µï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°")
    
    # æµ‹è¯•4: æ•°æ®æŠ“å–
    print("\n" + "="*70)
    print("æµ‹è¯•4: Arxivè®ºæ–‡æœç´¢")
    print("="*70)
    
    crawler = DataCrawler()
    
    try:
        papers = await crawler.search_arxiv("entropy information", max_results=2)
        print(f"\n  æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
        if len(papers) > 0:
            print(f"  ç¤ºä¾‹: {papers[0]['title'][:50]}...")
            print("  âœ… Arxivæœç´¢æ­£å¸¸")
    except Exception as e:
        print(f"  âš ï¸ Arxivæœç´¢å¤±è´¥: {e}")
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ")
    print("="*70)
    print("\næ ¸å¿ƒåŠŸèƒ½éªŒè¯:")
    print("  âœ“ è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆLLMï¼‰")
    print("  âœ“ å­¦ç§‘åˆ†ç±»ï¼ˆè§„åˆ™åŒ¹é…ï¼‰")
    print("  âœ“ è¿œäº²æ¦‚å¿µå‘ç°ç®—æ³•")
    print("  âœ“ æ•°æ®æŠ“å–ï¼ˆArxivï¼‰")
    print("\nâœ… é˜¶æ®µäºŒç®—æ³•æ¨¡å—å¯ç”¨äºè·¨å­¦ç§‘æ¦‚å¿µæœç´¢")
    print("="*70)
    
    return True


if __name__ == "__main__":
    try:
        asyncio.run(test_phase2_algorithms())
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
