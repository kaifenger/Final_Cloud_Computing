"""
è·¨å­¦ç§‘æ¦‚å¿µæŒ–æ˜æµ‹è¯•
éªŒè¯æ–°prompté€»è¾‘æ˜¯å¦èƒ½å‘ç°è¿œäº²æ¦‚å¿µ
"""
import asyncio
import httpx

BASE_URL = "http://localhost:8000/api/v1"

async def test_cross_discipline_discovery():
    """æµ‹è¯•è·¨å­¦ç§‘æ¦‚å¿µæŒ–æ˜"""
    test_cases = [
        {
            "concept": "ç¥ç»ç½‘ç»œ",
            "expectations": [
                "ç”Ÿç‰©ç¥ç»å…ƒï¼ˆç¥ç»ç§‘å­¦ï¼‰",
                "éœæ™®è²å°”å¾·ç½‘ç»œï¼ˆç»Ÿè®¡ç‰©ç†ï¼‰",
                "å›¾è®ºï¼ˆæ•°å­¦ï¼‰",
                "è´å¶æ–¯ç½‘ç»œï¼ˆæ¦‚ç‡è®ºï¼‰"
            ]
        },
        {
            "concept": "ç†µ",
            "expectations": [
                "ä¿¡æ¯ç†µï¼ˆä¿¡æ¯è®ºï¼‰",
                "çƒ­åŠ›å­¦ç†µï¼ˆçƒ­åŠ›å­¦ï¼‰",
                "ç»Ÿè®¡ç†µï¼ˆç»Ÿè®¡åŠ›å­¦ï¼‰",
                "äº¤å‰ç†µæŸå¤±ï¼ˆæœºå™¨å­¦ä¹ ï¼‰"
            ]
        },
        {
            "concept": "PageRankç®—æ³•",
            "expectations": [
                "é©¬å°”å¯å¤«é“¾ï¼ˆæ¦‚ç‡è®ºï¼‰",
                "éšæœºæ¸¸èµ°ï¼ˆç»Ÿè®¡ç‰©ç†ï¼‰",
                "å›¾è®ºï¼ˆæ•°å­¦ï¼‰",
                "ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ï¼ˆç½‘ç»œç§‘å­¦ï¼‰"
            ]
        },
        {
            "concept": "é—ä¼ ç®—æ³•",
            "expectations": [
                "è¾¾å°”æ–‡è¿›åŒ–è®ºï¼ˆç”Ÿç‰©å­¦ï¼‰",
                "è‡ªç„¶é€‰æ‹©ï¼ˆè¿›åŒ–ç”Ÿç‰©å­¦ï¼‰",
                "åŸºå› é‡ç»„ï¼ˆé—ä¼ å­¦ï¼‰",
                "ä¼˜åŒ–ç®—æ³•ï¼ˆè®¡ç®—æœºç§‘å­¦ï¼‰"
            ]
        }
    ]
    
    print("="*70)
    print("è·¨å­¦ç§‘æ¦‚å¿µæŒ–æ˜æµ‹è¯•")
    print("="*70)
    print(f"LLMæ¨¡å‹: Gemini 2.0 Flash Thinking")
    print(f"æ ¸å¿ƒç›®æ ‡: å‘ç°'è¿œäº²æ¦‚å¿µ' - ä¸åŒé¢†åŸŸä¸­åŸç†ç›¸é€šçš„æ¦‚å¿µ")
    print(f"æµ‹è¯•æ•°é‡: {len(test_cases)}ä¸ª")
    print("="*70)
    
    results = []
    
    async with httpx.AsyncClient(timeout=120.0) as client:
        for idx, test_case in enumerate(test_cases, 1):
            concept = test_case["concept"]
            expectations = test_case["expectations"]
            
            print(f"\n{'='*70}")
            print(f"[{idx}/{len(test_cases)}] æµ‹è¯•æ¦‚å¿µ: {concept}")
            print(f"{'='*70}")
            print(f"é¢„æœŸå‘ç°çš„è¿œäº²æ¦‚å¿µ:")
            for exp in expectations:
                print(f"  â€¢ {exp}")
            
            try:
                response = await client.post(
                    f"{BASE_URL}/discover",
                    json={"concept": concept, "max_concepts": 10}
                )
                
                if response.status_code == 200:
                    data = response.json()
                    nodes = data["data"]["nodes"]
                    metadata = data["data"].get("metadata", {})
                    
                    # æ’é™¤ä¸­å¿ƒèŠ‚ç‚¹
                    related_nodes = [n for n in nodes if n.get("depth", 1) == 1]
                    
                    # ç»Ÿè®¡å­¦ç§‘åˆ†å¸ƒ
                    print(f"\n[èŠ‚ç‚¹ç»Ÿè®¡]")
                    print(f"  æ€»èŠ‚ç‚¹æ•°: {len(nodes)} (1ä¸ªä¸­å¿ƒ + {len(related_nodes)}ä¸ªç›¸å…³)")
                    
                    disciplines = {}
                    for node in related_nodes:
                        disc = node.get("discipline", "æœªçŸ¥")
                        disciplines[disc] = disciplines.get(disc, 0) + 1
                    
                    print(f"\n[å­¦ç§‘åˆ†å¸ƒ] (è¦†ç›–{len(disciplines)}ä¸ªé¢†åŸŸ)")
                    for disc, count in sorted(disciplines.items(), key=lambda x: -x[1]):
                        print(f"  {disc}: {count}ä¸ª")
                    
                    # æ£€æŸ¥è·¨å­¦ç§‘è´¨é‡
                    if len(disciplines) >= 3:
                        print(f"\nâœ… è·¨å­¦ç§‘æŒ–æ˜æˆåŠŸï¼è¦†ç›–{len(disciplines)}ä¸ªä¸åŒé¢†åŸŸ")
                        cross_quality = "ä¼˜ç§€" if len(disciplines) >= 5 else "è‰¯å¥½"
                    else:
                        print(f"\nâš ï¸  å­¦ç§‘è¦†ç›–ä¸è¶³ï¼Œä»…{len(disciplines)}ä¸ªé¢†åŸŸ")
                        cross_quality = "å¾…æ”¹è¿›"
                    
                    # æ˜¾ç¤ºè¿œäº²æ¦‚å¿µç¤ºä¾‹
                    print(f"\n[è¿œäº²æ¦‚å¿µç¤ºä¾‹] (å‰5ä¸ª)")
                    for i, node in enumerate(related_nodes[:5], 1):
                        label = node.get("label", "")
                        disc = node.get("discipline", "æœªçŸ¥")
                        sim = node.get("similarity", 0)
                        cred = node.get("credibility", 0)
                        
                        # å°è¯•æ˜¾ç¤ºè·¨å­¦ç§‘åŸç†ï¼ˆå¦‚æœLLMè¿”å›äº†ï¼‰
                        definition = node.get("definition", "")
                        brief = node.get("brief_summary", "")
                        
                        print(f"\n  {i}. {label} ({disc})")
                        print(f"     ç›¸ä¼¼åº¦: {sim:.3f} | å¯ä¿¡åº¦: {cred:.3f}")
                        if brief:
                            print(f"     ç®€ä»‹: {brief[:100]}...")
                    
                    # åˆ†ææ˜¯å¦æ‰¾åˆ°é¢„æœŸçš„è¿œäº²æ¦‚å¿µ
                    found_expectations = []
                    for exp in expectations:
                        exp_name = exp.split("ï¼ˆ")[0]  # æå–æ¦‚å¿µå
                        for node in related_nodes:
                            if exp_name in node.get("label", ""):
                                found_expectations.append(exp)
                                break
                    
                    if found_expectations:
                        print(f"\n[é¢„æœŸåŒ¹é…] æ‰¾åˆ°{len(found_expectations)}/{len(expectations)}ä¸ªé¢„æœŸæ¦‚å¿µ:")
                        for exp in found_expectations:
                            print(f"  âœ“ {exp}")
                    
                    # å…ƒæ•°æ®
                    if metadata:
                        print(f"\n[å…ƒæ•°æ®]")
                        print(f"  ç”Ÿæˆæ–¹æ³•: {metadata.get('generation_method', 'N/A')}")
                        print(f"  å¹³å‡ç›¸ä¼¼åº¦: {metadata.get('avg_similarity', 0):.3f}")
                    
                    results.append({
                        "concept": concept,
                        "node_count": len(related_nodes),
                        "discipline_count": len(disciplines),
                        "quality": cross_quality,
                        "found_expectations": len(found_expectations),
                        "total_expectations": len(expectations)
                    })
                    
                else:
                    print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
                    results.append({
                        "concept": concept,
                        "error": f"HTTP {response.status_code}"
                    })
                
                await asyncio.sleep(3)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
                results.append({
                    "concept": concept,
                    "error": str(e)
                })
    
    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*70}")
    print("æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
    print(f"{'='*70}")
    
    successful = [r for r in results if "error" not in r]
    failed = [r for r in results if "error" in r]
    
    print(f"\næ€»æµ‹è¯•æ•°: {len(test_cases)}")
    print(f"æˆåŠŸ: {len(successful)}")
    print(f"å¤±è´¥: {len(failed)}")
    
    if successful:
        print(f"\n[æˆåŠŸæ¡ˆä¾‹è¯¦æƒ…]")
        for r in successful:
            quality_icon = "ğŸŒŸ" if r["quality"] == "ä¼˜ç§€" else "âœ…" if r["quality"] == "è‰¯å¥½" else "âš ï¸"
            print(f"\n{quality_icon} {r['concept']}")
            print(f"  èŠ‚ç‚¹æ•°: {r['node_count']}")
            print(f"  å­¦ç§‘è¦†ç›–: {r['discipline_count']}ä¸ªé¢†åŸŸ")
            print(f"  è´¨é‡è¯„ä»·: {r['quality']}")
            print(f"  é¢„æœŸåŒ¹é…: {r['found_expectations']}/{r['total_expectations']}")
    
    if failed:
        print(f"\n[å¤±è´¥æ¡ˆä¾‹]")
        for r in failed:
            print(f"âŒ {r['concept']}: {r['error']}")
    
    # æ€»ä½“è¯„ä»·
    if len(successful) == len(test_cases):
        avg_disciplines = sum(r["discipline_count"] for r in successful) / len(successful)
        if avg_disciplines >= 4:
            print(f"\nğŸ‰ æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼å¹³å‡å­¦ç§‘è¦†ç›–: {avg_disciplines:.1f}ä¸ª")
            print(f"   è·¨å­¦ç§‘æŒ–æ˜èƒ½åŠ›: ä¼˜ç§€")
        else:
            print(f"\nâœ… æµ‹è¯•é€šè¿‡ï¼Œä½†å­¦ç§‘è¦†ç›–æœ‰å¾…æå‡")
            print(f"   å¹³å‡å­¦ç§‘è¦†ç›–: {avg_disciplines:.1f}ä¸ªï¼ˆç›®æ ‡: â‰¥4ä¸ªï¼‰")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡å’ŒAPIé…ç½®")
    
    return results


if __name__ == "__main__":
    print(__doc__)
    asyncio.run(test_cross_discipline_discovery())
