"""
Gemini 3 Flash é…ç½®éªŒè¯è„šæœ¬
éªŒè¯æ–°LLMé…ç½®æ˜¯å¦æ­£ç¡®å·¥ä½œ
"""
import asyncio
import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path)

async def test_gemini_3_flash():
    """æµ‹è¯•Gemini 3 Flashé…ç½®"""
    print("="*70)
    print("Gemini 3 Flash é…ç½®éªŒè¯")
    print("="*70)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\n[1] æ£€æŸ¥ç¯å¢ƒå˜é‡")
    api_key = os.getenv("OPENROUTER_API_KEY")
    base_url = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
    model = os.getenv("LLM_MODEL", "google/gemini-3-flash-preview")
    
    if not api_key:
        print("âŒ OPENROUTER_API_KEY æœªè®¾ç½®")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ï¼šOPENROUTER_API_KEY=your_key")
        return
    else:
        print(f"âœ… OPENROUTER_API_KEY: {api_key[:20]}...")
    
    print(f"âœ… OPENROUTER_BASE_URL: {base_url}")
    print(f"âœ… LLM_MODEL: {model}")
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    print("\n[2] åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯")
    try:
        client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url
        )
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•åŸºæœ¬è°ƒç”¨
    print("\n[3] æµ‹è¯•åŸºæœ¬LLMè°ƒç”¨ï¼ˆä¸å¯ç”¨reasoningï¼‰")
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": "ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ"}
                ],
                temperature=0.3,
                max_tokens=100
            ),
            timeout=30.0
        )
        
        if response and response.choices:
            answer = response.choices[0].message.content.strip()
            print(f"âœ… LLMå“åº”æˆåŠŸ")
            print(f"   å›ç­”: {answer[:100]}...")
        else:
            print("âŒ å“åº”æ ¼å¼é”™è¯¯")
    except asyncio.TimeoutError:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•reasoningæ¨¡å¼
    print("\n[4] æµ‹è¯•Reasoningæ¨¡å¼ï¼ˆå¯ç”¨æ¨ç†ï¼‰")
    try:
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": "ç¥ç»ç½‘ç»œå’Œç”Ÿç‰©ç¥ç»å…ƒæœ‰ä»€ä¹ˆæ·±å±‚è”ç³»ï¼Ÿ"
                    }
                ],
                temperature=0.4,
                max_tokens=200,
                extra_body={"reasoning": {"enabled": True}}
            ),
            timeout=30.0
        )
        
        if response and response.choices:
            message = response.choices[0].message
            answer = message.content.strip()
            
            print(f"âœ… Reasoningæ¨¡å¼å“åº”æˆåŠŸ")
            print(f"   å›ç­”: {answer[:150]}...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰reasoning_details
            if hasattr(message, 'reasoning_details') and message.reasoning_details:
                print(f"   âœ… åŒ…å«æ¨ç†ç»†èŠ‚: {message.reasoning_details}")
            else:
                print(f"   â„¹ï¸  æœªè¿”å›æ¨ç†ç»†èŠ‚ï¼ˆå¯èƒ½æ¨¡å‹ä¸æ”¯æŒæˆ–æœªè¾“å‡ºï¼‰")
        else:
            print("âŒ å“åº”æ ¼å¼é”™è¯¯")
    except asyncio.TimeoutError:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
    except Exception as e:
        print(f"âŒ Reasoningè°ƒç”¨å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•è·¨å­¦ç§‘æ¦‚å¿µç”Ÿæˆ
    print("\n[5] æµ‹è¯•è·¨å­¦ç§‘æ¦‚å¿µç”Ÿæˆ")
    try:
        prompt = """ä½ æ˜¯è·¨å­¦ç§‘çŸ¥è¯†æŒ–æ˜ä¸“å®¶ã€‚è¯·ä¸ºæ¦‚å¿µ"ç†µ"ç”Ÿæˆ3ä¸ªè·¨å­¦ç§‘çš„ç›¸å…³æ¦‚å¿µã€‚

å¿…é¡»ä»ä¸åŒé¢†åŸŸå¯»æ‰¾ï¼ˆç‰©ç†å­¦ã€ä¿¡æ¯è®ºã€ç»Ÿè®¡å­¦ç­‰ï¼‰ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ï¼š
æ¦‚å¿µå|å­¦ç§‘|å…³ç³»ç±»å‹|è·¨å­¦ç§‘åŸç†

è¯·ç›´æ¥è¾“å‡ºï¼š"""
        
        response = await asyncio.wait_for(
            client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯è·¨å­¦ç§‘çŸ¥è¯†æŒ–æ˜ä¸“å®¶ï¼Œæ“…é•¿å‘ç°ä¸åŒé¢†åŸŸé—´çš„æ·±å±‚åŸç†å…³è”ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=300,
                extra_body={"reasoning": {"enabled": True}}
            ),
            timeout=30.0
        )
        
        if response and response.choices:
            answer = response.choices[0].message.content.strip()
            print(f"âœ… è·¨å­¦ç§‘ç”ŸæˆæˆåŠŸ")
            print(f"   ç»“æœ:")
            for line in answer.split('\n')[:5]:
                if line.strip():
                    print(f"      {line.strip()}")
            
            # éªŒè¯æ ¼å¼
            if '|' in answer:
                print(f"   âœ… è¾“å‡ºæ ¼å¼æ­£ç¡®ï¼ˆåŒ…å«ç®¡é“ç¬¦ï¼‰")
            else:
                print(f"   âš ï¸  è¾“å‡ºæ ¼å¼å¯èƒ½éœ€è¦è°ƒæ•´")
        else:
            print("âŒ å“åº”æ ¼å¼é”™è¯¯")
    except asyncio.TimeoutError:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
    except Exception as e:
        print(f"âŒ è·¨å­¦ç§‘ç”Ÿæˆå¤±è´¥: {e}")
        return
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("éªŒè¯æ€»ç»“")
    print("="*70)
    print(f"âœ… ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®")
    print(f"âœ… OpenAIå®¢æˆ·ç«¯å·¥ä½œæ­£å¸¸")
    print(f"âœ… Gemini 3 Flashæ¨¡å‹å¯è®¿é—®")
    print(f"âœ… Reasoningæ¨¡å¼å·²å¯ç”¨")
    print(f"âœ… è·¨å­¦ç§‘Promptå·¥ä½œæ­£å¸¸")
    print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ç³»ç»Ÿã€‚")


async def test_similarity_calculation():
    """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆéœ€è¦OpenAI APIï¼‰"""
    print("\n" + "="*70)
    print("ç›¸ä¼¼åº¦è®¡ç®—æµ‹è¯•ï¼ˆå¯é€‰ï¼‰")
    print("="*70)
    
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âš ï¸  OPENAI_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ç›¸ä¼¼åº¦æµ‹è¯•")
        print("   ç›¸ä¼¼åº¦è®¡ç®—éœ€è¦OpenAI APIå¯†é’¥")
        return
    
    print(f"âœ… OPENAI_API_KEY: {openai_key[:20]}...")
    
    try:
        from openai import AsyncOpenAI
        import numpy as np
        
        client = AsyncOpenAI(api_key=openai_key)
        
        # æµ‹è¯•embedding
        concept1 = "ç¥ç»ç½‘ç»œ"
        concept2 = "æ·±åº¦å­¦ä¹ "
        
        print(f"\nè®¡ç®—ç›¸ä¼¼åº¦: '{concept1}' <-> '{concept2}'")
        
        response1 = await client.embeddings.create(
            model="text-embedding-3-small",
            input=concept1
        )
        response2 = await client.embeddings.create(
            model="text-embedding-3-small",
            input=concept2
        )
        
        embedding1 = np.array(response1.data[0].embedding)
        embedding2 = np.array(response2.data[0].embedding)
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        cosine_sim = np.dot(embedding1, embedding2) / (
            np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
        )
        similarity = float(max(0, min(1, (cosine_sim + 1) / 2)))
        
        print(f"âœ… ç›¸ä¼¼åº¦è®¡ç®—æˆåŠŸ: {similarity:.3f}")
        
        if similarity > 0.8:
            print(f"   è¯„ä»·: é«˜åº¦ç›¸å…³ï¼ˆå¼ºå…³è”ï¼‰")
        elif similarity > 0.6:
            print(f"   è¯„ä»·: ä¸­åº¦ç›¸å…³ï¼ˆæ‰©å±•æ¦‚å¿µï¼‰")
        else:
            print(f"   è¯„ä»·: å¼±ç›¸å…³ï¼ˆè¾¹ç¼˜æ¦‚å¿µï¼‰")
        
    except ImportError:
        print("âŒ ç¼ºå°‘numpyåº“ï¼Œè¯·å®‰è£…: pip install numpy")
    except Exception as e:
        print(f"âŒ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")


if __name__ == "__main__":
    print(__doc__)
    asyncio.run(test_gemini_3_flash())
    asyncio.run(test_similarity_calculation())
